{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логистическая регрессия\n",
    "\n",
    "## Задача классификации\n",
    "\n",
    "Рассмотренные ранее регрессионные модели подразумевают, что целевая переменная $Y$ является *количественной*. Однако, зачастую независимая переменная является *качественной*.\n",
    "Например, цвет глаз - качественная переменная.\n",
    "Часто качественные переменные называют *категориальными* (эти термины взаимозаменяемы). Предсказание качественного отклика для некоторого наблюдения можно назвать классификацией, поскольку это наблюдение относят к определенной категории (классу). \n",
    "\n",
    "С другой стороны, методы классификации часто в качестве основы для выполнения классификации сначала предсказывают вероятность каждой из категорий качественной переменной и в этом смысле они ведут себя подобно методам регрессии.\n",
    "\n",
    "**Примеры задач классификации:**\n",
    "* Определить, входящий e-mail спам, или нет?\n",
    "* Определить, является ли банковская транзакция мошеннической, или нет?\n",
    "* Определить, опухоль является злокачественной или доброкачественной?\n",
    "\n",
    "Что объединяет примеры выше?\n",
    "У всех этих примеров ответ целевой переменной да или нет. Таким образом, $Y = \\{0,1\\}$, т.е. мы имеем дело с **бинарной классификацией**.\n",
    "Т.е. \n",
    "* $Y = 1$ - позитивный класс (Positive class) - часто выражает присутствие чего-либо;\n",
    "* $Y = 0$ - негативный класс (Negative class) - часто выражает отсутствие чего-либо;\n",
    "\n",
    "Мы начнем рассмотрение бинарной классификации, и затем рассмотрим многоклассовую классификацию (хотя, по своей сути она просто расширение бинарной классификации).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Наивный Байесовский классификатор\n",
    "\n",
    "Наивная Байесовская классификация - один из самых элегантных практически используемых алгоритмов машинного обучения. Он является мощным и эффективным инструментов по качеству результата.\n",
    "\n",
    "* Устойчив к нерелевантным признакам, которые просто игнорирует\n",
    "* Быстро обучается и быстро возвращает предсказание\n",
    "* Потребляет относительно небольшое число ресурсов\n",
    "\n",
    "В чем же наивность?\n",
    "\n",
    "Наивность относится к предположению, необходимому для оптимальной работы классификатора. Состоит оно в том, что признаки не влияют друг на друга. В реальности такое бывает крайне редко, но на практике верность этого алгоритма достаточно выскоа, даже если предположение о независимости признаков не оправдывается.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теорема Байеса\n",
    "\n",
    "По сути, наивная Байесовская классификация - не что иное, как отслеживание того, какой признак о каком классе свидетельствует. Способ проектирования признаков определяет модель, используемую для обучения.\n",
    "\n",
    "Например, в **модели Бернулли** допускаются только буоевские признаки (встречается слово один или несколько раз не имеет значения). В мультиномиальной модели признаками являются счетчики слов.\n",
    "\n",
    "Пока рассмотрим модель Бернулли, чтобы объяснить как наивный Байесовский классификатор используется для анализа эмоциональной окраски текста. А для обучения и настройки реальных классификаторов (позже) перейдем на **мультиномиальную модель**.\n",
    "\n",
    "Итак, пусть:\n",
    "* $C$ - Класс твита (положительный или отрицательный);\n",
    "* $F_1$ - В твите хотя бы раз встречается слово awesome;\n",
    "* $F_2$ - В твите хоть раз встречается слово crazy\n",
    "\n",
    "В ходе обучения мы построили наивную Байесовскую модель, которая возвращает вероятность класса $C$, если известны признаки $F_1$ и $F_2$. Эта вероятность записывается в виде $\\Pr(C\\mid F_1, F_2)$.\n",
    "\n",
    "Поскольку мы не можем оценить  $\\Pr(C\\mid F_1, F_2)$ непосредственно, то применим формулу, изобретенную Байесом:\n",
    " $$\\Pr(B)\\times\\Pr(B\\mid A) = \\Pr(A)\\times\\Pr(A\\mid B)$$ или $$ \\Pr(B \\mid A) = \\frac{\\Pr(A)\\times\\Pr(A \\mid B)}{\\Pr(B)}$$\n",
    " \n",
    "Если считать, что $A$ - событие.ю состоящее во вхождении обоих слов awesome и crazy, а $B$ - принадлежность твита классу $C$, то получится формула, которая впоследствии может помочь нам вычислить вероятность принадлежности образца к указанному классу:\n",
    "\n",
    "$$\\Pr(F_1, F_2) \\times \\Pr(C\\mid F_1, F_2) = \\Pr(C)\\times\\Pr(F_1, F_2\\mid C).$$\n",
    "\n",
    "Это позволяет выразить $\\Pr(C\\mid F_1, F_2)$ через другие вероятности:\n",
    "\n",
    "$$\\Pr(C\\mid F_1, F_2) = \\frac{\\Pr(C)\\times \\Pr(F_1, F_2\\mid C)}{\\Pr(F_1, F_2)}$$\n",
    "\n",
    "Можно и записать в таком виде:\n",
    "\n",
    "$$prior = \\frac{posterior \\times likelihood}{evidence}$$\n",
    "\n",
    "$prior$ м $evidence$ найти легко:\n",
    "* $P(C)$ - априорная вероятность класса без каких-либо знаний о данных. Оценить её можно напрямую подсчитав долю обучающих примеров, принадлежащих данному классу.\n",
    "* $P(F_1, F_2)$ - свидетельство, или вероятность одновременного наличия признаков $F_1$ и  $F_2$.\n",
    "\n",
    "Нетривиальная часть - вычисление правдоподобия (likelihood) $\\Pr(F_1, F_2\\mid C)$. Эта величина говорит о том, насколько вероятно увидеть признаки $F_1$ и  $F_2$, если мы знаем, что образец принадлежит классу $C$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предположение о наивности\n",
    "Из теории вероятностей:\n",
    "$$ \\Pr(F_1, F_2 \\mid C) = \\Pr(F_1 \\mid C) \\times \\Pr(F_2 \\mid C, F_1).$$\n",
    "\n",
    "Сама по себе формула мало что дает, поскольку мы заменяем одну трудную задачу - поиск $\\Pr(F_1, F_2 \\mid C)$ другой, не менее трудной - оценка $ \\Pr(F_2 \\mid C, F_1)$.\n",
    "\n",
    "Однако, если наивно предположить, что $F_1$ и $F_2$ независимы, то $ \\Pr(F_2 \\mid C, F_1)$ сводится к $ \\Pr(F_2 \\mid C)$ и мы можем записать:\n",
    "$$\\Pr(F_1, F_2 \\mid C) = \\Pr(F_1 \\mid C)\\times\\Pr(F_2 \\mid C).$$\n",
    "\n",
    "Собирая всё вместе, получаем простую формулу:\n",
    "$$\\Pr(C\\mid F_1, F_2) = \\frac{\\Pr(C)\\times\\Pr(F_1 \\mid C) \\Pr(F_2 \\mid C)}{\\Pr(F_1, F_2)}$$.\n",
    "\n",
    "Любопытная вещь: хотя теоретически неправильно выдвигать произвольные предположения под настроение, в данном случае такой подход на удивление хорошо работает в реальных задачах.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Использование наивного Байесовского алгоритма для классификации\n",
    "\n",
    "Итак, получив новый твит, мы должны вычислить вероятности:\n",
    "\n",
    "$$\\Pr(C = \\text{\"pos\"} \\mid F_1, F_2) = \\frac{\\Pr(C = \\text{\"pos\"})\\times\\Pr(F_1 \\mid \\text{C = \"pos\"}) \\times \\Pr(F_2 \\mid C = \\text{\"pos\"})}{\\Pr(F_1, F_2)}$$.\n",
    "\n",
    "$$\\Pr(C = \\text{\"neg\"} \\mid F_1, F_2) = \\frac{\\Pr(C = \\text{\"neg\"} )\\times\\Pr(F_1 \\mid C = \\text{\"neg\"} ) \\times\\Pr(F_2 \\mid C = \\text{\"pos\"} )}{\\Pr(F_1, F_2)}$$.\n",
    "\n",
    "А затем выбрать класс $C_{best}$ с наибольшей вероятностью.\n",
    "\n",
    "\n",
    "Поскольку для обоих классов знаменатель одинаковый мы его можем просто игнорировать - предсказанный класс от этого не изменится.\n",
    "\n",
    "\n",
    "Однако, стоит отметить, что реальные вероятности больше не вычисляются Вместо этого оценивается, какой класс более правдоподобен, по имеющимся свидетельствам. Это еще одна причина устойчивости наивного байесовского классификатора: его интересуют не столько истинные вероятности, сколько информация о том, какой клсс правдоподобнее.\n",
    "\n",
    "Короче говоря, можно написать:\n",
    "$$C_{best} = \\arg\\max_{c\\in C} \\Pr(C=c)\\times\\Pr(F_1\\mid C=c)\\times\\Pr(F_2\\mid C=c)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Говоря, что мы вычисляем часть после $\\arg\\max$ для всех классов и возвращаем тот класс, для которого получилось наибольшее значение.\n",
    "\n",
    "Проиллюстрируем, чтобы понаблюдать за работой наивного байесовского алгоритма. Сделаем предположение, что Twitter разрешает употреблять только два слова: awesome и crazy и что мы уже вручную проклассифицировали несколько твитов:\n",
    "\n",
    "| Твит | Класс \n",
    "| :-:  | :-:\n",
    "|awesome | pos\n",
    "|awesome | pos\n",
    "|awesome crazy | pos\n",
    "|crazy | pos\n",
    "|crazy | neg\n",
    "|crazy | neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Твит crazy получил как отрицательную, так и положительную оценку (моделируем реальныую речь: \"балдеть от футбола\" и \"дурацкий идиот\").\n",
    "Всего шесть твитов - 4 pos и 2 neg, поэтому получаем априорные вероятности:\n",
    "$$\\Pr(C=pos) = \\frac{4}{6} ~ 0.67$$\n",
    "$$\\Pr(C=neg) = \\frac{2}{6} ~ 0.33$$\n",
    "\n",
    "Это означает, что ничего не зная о самом твите, разумно предположить что он положительный.\n",
    "\n",
    "Пока отсутсвует вычисление $\\Pr(F_1\\mid C=c)$ и $\\Pr(F_2\\mid C=c)$ - вероятностей признаков $F_1$ и $F_2$ при условии класса $C$. Они вычисляются как количество твитов, в которых встречался отдельный признак, поделенное на количество твитов помеченных классом $C$.\n",
    "\n",
    "Вероятность встретить awesome, если известно что класс положительный:\n",
    "$$\\Pr(F_1 = 1 \\mid C=pos) = \\frac{\\text{число положительных твитов, содержащих слово awesome}}{\\text{число всех положительных твитов}} = \\frac{3}{4}$$\n",
    "Поскольку из 4 положительных твитов 3 содержали слово awesome.\n",
    "\n",
    "Очевидно, что вероятность не встретить слово awesome в положительном твите равна:\n",
    "$$\\Pr(F_1 = 0 \\mid C=pos) = 1 - \\Pr(F_1 = 1 \\mid C=pos) = 0.25$$\n",
    "\n",
    "Точно так же производятся остальные вычисления.\n",
    "$$\\Pr(F_2 = 1 \\mid C=pos)$$\n",
    "$$\\Pr(F_1 = 1 \\mid C=neg)$$\n",
    "$$\\Pr(F_2 = 1 \\mid C=neg)$$\n",
    "\n",
    "Для полноты картины вычислим свидетельство, чтобы узнать истинные вероятности. Для двух конкретных щначений $F_1$ и $F_2$ свидел=тельство вычисляет ся так:\n",
    "$$\\Pr(F_1, F_2) = \\Pr(F_1, F_2 \\mid C=pos)\\Pr(C=pos) + \\Pr(F_1, F_2 \\mid C=neg)\\Pr(C=neg).$$\n",
    "\n",
    "Пока всё хорошо. При классификации тривиальных твитов метки, похоже вычисляются корректно. \n",
    "\n",
    "Но как быть со словами не встречавшихся в тренировочном корпусе? Ведь всем новым словам будет присвоена нулевая вероятность.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Учет ранее не встречавшихся слов\n",
    "\n",
    "Ранее мы вычисляли не истинные вероятности а лишь грубые приближения к ним. Мы предполагали, что тренировочный корпус содержит полную информацию об истинных вероятностях.\n",
    "\n",
    "Но это не так!\n",
    "\n",
    "Очевидно, что 6 твитов не дадут всю информацию о каждом из когда то написанных твитов. Например, существуют твиты содержащие слово text. Просто мы их не видели. Следовательно, наше приближение очень грубое и нужно учитывать это.\n",
    "\n",
    "На практике для этого часто применяется **сглаживание с прибавлением единицы (add-one smoothing)**.\n",
    "Это очень простой приём, заключающийся в прибавлении единицы ко всем вхождениям признака. В его основе лежит предположение, что даже если мы не видели данного слова во всем корпусе, есть шанс , что это случилось только потому, что в нашей выборке таких твитов не оказалось. \n",
    "\n",
    "То есть вместо вычисления:\n",
    "\n",
    "$$\\Pr(F_1 = 1 \\mid C=pos) = \\frac{\\text{число положительных твитов, содержащих слово awesome}}{\\text{число всех положительных твитов}} = \\frac{3}{4} = 0.75$$\n",
    "Мы вычисляем:\n",
    "$$\\Pr(F_1 = 1 \\mid C=pos) = \\frac{3+1}{4+2}=0.67$$\n",
    "\n",
    "Почему в знаменателе прибавлено 2? \n",
    "Потому что всего у нас два признака: вхождения слов awesome и crazy. Поскольку мы прибавляем 1 для каждого признака нужно позаботиться, чтобы получились всё же вероятности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Потеря точности?\n",
    "Еще одна проблема - вещественная арифметика.\n",
    "Но мы можем прологарифмировать:\n",
    "$ \\log(x,y) = \\log(x) +\\log(y)$\n",
    "\n",
    "В применении к нашему случаю:\n",
    "$$\\log(\\Pr(C)\\times\\Pr(F_1 \\mid C)\\times\\Pr(F_2 \\mid C)) = \\log\\Pr(C) + \\log\\Pr(F_1 \\mid C) + \\log\\Pr(F_2 \\mid C)$$\n",
    "\n",
    "Вероятность лежит в интервале от 0 до 1, значит её логарифм лежит в интервале от $-\\inf$ до 0. Но по прежнему, чем больше число, тем точнее определен класс, только числа теперь отрицательны.\n",
    "\n",
    "Но проблема еще есть: в числителе дроби нет никакого логарифма, а есть лишь произведение вероятностей. К счастью, фактические значения вероятностей нам неизвестны, а нужно знать у какого класса максимальная апостериорная вероятность.\n",
    "\n",
    "И тут нам повезло, потому что если верно, что $\\Pr(C=pos\\mid F_1, F_2) > \\Pr(C=neg \\mid F_1, F_2)$, то верно и то, что $\\log\\Pr(C=pos\\mid F_1, F_2) > \\log\\Pr(C=neg \\mid F_1, F_2)$.\n",
    "\n",
    "Кривая монотонно возрастает, поэтому можно воспользоваться формулой:\n",
    "$$C_{best} = \\arg\\max_{c\\in C} \\Pr(C=c)\\times\\Pr(F_1\\mid C=c)\\times\\Pr(F_2\\mid C=c)$$\n",
    "\n",
    "Откуда мы получаем формулу для двух признаков, которая дает наилучший класс даже для образцов, которые мы ранее не видели:\n",
    "$$C_{best} = \\arg\\max_{c\\in C} (\\log\\Pr(C=c)+\\log\\Pr(F_1\\mid C=c)+\\log\\Pr(F_2\\mid C=c)$$\n",
    "\n",
    "Разумеется, двух признаков маловато, поэтому обобщим на произвольное число признаков:\n",
    "$$C_{best} = \\arg\\max_{c\\in C} (\\log\\Pr(C=c)+\\sum_{k}\\log\\Pr(F_k\\mid C=c)).$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как построить наивный Байесовский классификатор в Python?\n",
    "\n",
    "Scikit-learn имеет 3 модели наивного Байесовского классификатор. \n",
    "* Gaussian: Используется в классификации и предполагает, что атрибуты нормально распределены.\n",
    "* Multinomial: Используется для дискретных атрибутов. (Например, текстовая классификация - можно рассмотреть модель Бернулли, и говорить о том, встречаается ли слово в тексте, или нет, а можно подсчитать, как часто слово встречается в документе. Можно рассматривать как \"число раз, когда атрибут $x_i$ наблюдается.\n",
    "* Bernoulli: Биномиальная модель полезна в том случае, если вектор атрибутов является бинарным. (Пример: классификация текстов, с моделью bag of words, где атрибуты могут быть 0 (слово не встретилось) или 1 (слово встретилось).\n",
    "\n",
    "Ниже рассмотрен пример использования Гауссовской модели наивного Байесовского классификатора.Gaussian model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4]\n"
     ]
    }
   ],
   "source": [
    "#Import Library of Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "\n",
    "#assigning predictor and target variables\n",
    "x= np.array([[-3,7],[1,5], [1,2], [-2,0], [2,3], [-4,0], [-1,1], [1,1], [-2,2], [2,7], [-4,1], [-2,7]])\n",
    "Y = np.array([3, 3, 3, 3, 4, 3, 3, 4, 3, 4, 4, 4])\n",
    "#Create a Gaussian Classifier\n",
    "model = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets \n",
    "model.fit(x, Y)\n",
    "\n",
    "#Predict Output \n",
    "predicted= model.predict([[1,2],[3,4]])\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Полезные ссылки\n",
    "* https://www.analyticsvidhya.com/blog/2015/09/naive-bayes-explained/\n",
    "* Building Machine Learning Systems with Python (Authors: Willi Richert, Luis Pedro Coelho)\n",
    "* An Introduction to Statistical Learning with Applications in R (Authors: Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani), http://www-bcf.usc.edu/~gareth/ISL/\n",
    "* Machine Learning in Action (Author: Peter Harrington)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбор задачи\n",
    "\n",
    "Пусть дана обучающая выборка с информацией о погоде и соответствующая целевая переменная 'Play'. Сейчас, мы хотим классифицировать, будут ли игроки играть или нет в зависимости от погодных условий.\n",
    "\n",
    "| Weather | Play\n",
    "| :-:  | :-:\n",
    "| Sunny | No\n",
    "| Overcast | Yes\n",
    "| Rainy | Yes\n",
    "| Sunny | Yes\n",
    "| Sunny | Yes\n",
    "| Overcast | Yes\n",
    "| Rainy | No\n",
    "| Rainy | No\n",
    "| Sunny | Yes\n",
    "| Rainy | Yes\n",
    "| Sunny | No\n",
    "| Overcast | Yes\n",
    "| Overcast | Yes\n",
    "| Rainy | No\n",
    "\n",
    "\n",
    "**Шаг 1**: Преобразуем исходные данные в частотную таблицу;\n",
    "\n",
    "Frequency Table:\n",
    "\n",
    "| Weather | No | Yes\n",
    "| :-:  | :-: | :-: \n",
    "| Overcase |  | 4\n",
    "| Rainy | 3 | 2\n",
    "| Sunny | 2 | 3\n",
    "| Grand Total | 5 | 9\n",
    "\n",
    "\n",
    "**Шаг 2**: Создать таблицу правдоподобия (likelihood table);\n",
    "\n",
    "| Weather | No | Yes \n",
    "| :-:  | :-: | :-: \n",
    "| Overcase |  | 4 | = 4/14 | 0.29\n",
    "| Rainy | 3 | 2 | = 5/14 | 0.36\n",
    "| Sunny | 2 | 3 | = 5/14 | 0.36\n",
    "| All | 5 | 9\n",
    "| | =5/14 | =9/14\n",
    "| | 0.36 | 0.64\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Шаг 3 **: Используем предположение о наивности для вычисления апостериорной вероятности для каждого класса. Класс с максимальной апостериорной вероятностью и является результатом предсказания\n",
    "\n",
    "\n",
    "** Проблема: Является ли истинным утверждение, что игроки будут играть, если погода солнечная (Sunny)**\n",
    "\n",
    "Мы можем решить, исходя из предложенного на лекции метода вычисления апостериорной вероятности.\n",
    "\n",
    "$$ \\Pr(Yes \\mid Sunny) = \\frac{\\Pr(Sunny \\mid Yes) \\times \\Pr(Yes)}{\\Pr(Sunny)} \\sim \\Pr(Sunny \\mid Yes) \\times \\Pr(Yes)$$\n",
    "\n",
    "Поскольку, $$\\Pr(Sunny \\mid Yes) = \\frac{3}{9} = 0.33,$$ $$\\Pr(Sunny) = \\frac{5}{14}=0.36,$$ $$\\Pr(Yes) = \\frac{9}{14}=0.64$$.\n",
    "Итак, $$\\Pr(Yes \\mid Sunny)=\\frac{0.33\\times 0.64}{0.36} = 0.60.$$\n",
    "\n",
    "Правдоподобие: $$\\Pr(Yes \\mid Sunny)=\\frac{0.33\\times 0.64} = 0.2112$$\n",
    "\n",
    "$$ \\Pr(No \\mid Sunny) = \\frac{\\Pr(Sunny \\mid No) \\times \\Pr(No)}{\\Pr(Sunny)} \\sim \\Pr(Sunny \\mid No) \\times \\Pr(No)$$\n",
    "Поскольку, $$\\Pr(Sunny \\mid No) = \\frac{2}{5} = 0.4,$$ $$\\Pr(Sunny) = \\frac{5}{14}=0.36,$$ $$\\Pr(No) = \\frac{5}{14}=0.36.$$\n",
    "Итак, $$\\Pr(No \\mid Sunny)=\\frac{0.4 \\times 0.36}{0.36} = 0.60$$\n",
    "\n",
    "Правдоподобие: $$\\Pr(No \\mid Sunny)=\\frac{0.33\\times 0.64} = 0.144$$\n",
    "\n",
    "Правдоподобие (равно как и вероятность $\\Pr(Yes \\mid Sunny)$) больше по сравнению с правдоподобием (или вероятностью  $\\Pr(No \\mid Sunny)$).\n",
    "\n",
    "**Ответ: ** игра состоится.\n",
    "\n",
    "Наивный Байесовский алгоритм имеет похожий метод для предсказания вероятности разных классов, который базируется на различных атрибутах. Алгоритм широко используется в классификации текстов и с проблемами, имеющими несколько классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проблема переобучения и борьба с переобучением. Регуляризация.\n",
    "\n",
    "## Проблема переобучения\n",
    "\n",
    "### Пример: проблема переобучения в задачах классификации\n",
    "\n",
    "Допустим при решении задачи классификации был построен некоторый алгоритм, например линейный классификатор, причем доля ошибок на объектах из обучающей выборки была равна 0.2, и такая доля ошибок является допустимой.\n",
    "\n",
    "Но поскольку алгоритм не обладает обобщающей способностью, нет никаких гарантий, что такая же доля ошибок будет для новой выборки. Вполне может возникнуть ситуация, что для новой выборки ошибка станет равной 0.9. Это значит, что алгоритм не смог обобщить обучающую выборку, не смог извлечь из нее закономерности и применить их для классификации новых объектов. При этом алгоритм как-то смог подогнаться под обучающую выборку и показал хорошие результаты при обучении без извлечения истинной\n",
    "закономерности. В этом и состоит **проблема переобучения**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Пример: проблема переобучения в задачах линейной регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Глубже понять проблему переобучения можно на данном примере. На следующем графике изображена истинная зависимость и объекты обучающей выборки:\n",
    "![](img\\Overfitting\\img1.png)\n",
    "<h4 align=\"center\">Рис. 1: Истинная зависимость (зеленая линия) и элементы обучающей выборки (изображены синими точками).</h4> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что истинная зависимость является нелинейной и имеет два экстремума.\n",
    "\n",
    "В модели $a(x) = w_0$, после того, как она будет настроена под данные, на графике получается некоторая горизонтальная кривая, которая довольно плохо обобщает информацию об объектах из выборки.\n",
    "![](img\\Overfitting\\img2.png)\n",
    "<h4 align=\"center\">Рис. 2: Модель $a(x) = w_0$.</h4> \n",
    "\n",
    "Имеет место недообучение. Хороший алгоритм не был построен, поскольку семейство алгоритмов слишком мало и с его помощью невозможно уловить закономерность.\n",
    "\n",
    "В линейной регрессии используется семейство алгоритмов $a(x) = w_0 + w_1x$.\n",
    "![](img\\Overfitting\\img3.png)\n",
    "<h4 align=\"center\">Рис. 3: Модель $a(x) = w_0 + w_1x$.</h4> \n",
    "\n",
    "В этом случае также будет иметь место недообучение. Получилось лучше, но прямая тоже плохо описывает данные.\n",
    "Если семейство алгоритмов — множество многочленов 4-ей степени:\n",
    "$a(x) = w_0 + w_1x + w_2x^2 + \\ldots + w_4x^4$\n",
    "то после обучения получившаяся кривая будет достаточно хорошо описывать и обучающую выборку, и истинную зависимость.\n",
    "![](img\\Overfitting\\img4.png)\n",
    "<h4 align=\"center\">Рис. 4: Модель $a(x) = w_0 + w_1x + w_2x^2 + \\ldots + w_4x^4$.</h4> \n",
    "\n",
    "В таком случае качество алгоритма хорошее, но нет идеального совпадения. Встает вопрос, а можно ли добиться совпадения увеличением сложности алгоритма.\n",
    "При использовании многочленов 9-ой степени уже имеет место переобучение.\n",
    "![](img\\Overfitting\\img5.png)\n",
    "<h4 align=\"center\">Рис. 5: Модель $a(x) = w_0 + w_1x + w_2x^2 + \\ldots + w_9x^9$.</h4> \n",
    "\n",
    "Восстановленная зависимость дает идеальные ответы на всех объектах обучающей выборки, но при этом в любой другой точке сильно отличается от истинной зависимости. Такая ситуация называется **переобучением**.\n",
    "\n",
    "Алгоритм слишком сильно подогнался под обучающую выборку ценой того, что он будет давать плохие ответы на новых точках."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Недообучение и переобучение\n",
    "Таким образом, недообучение — ситуация, когда алгоритм плохо описывает и обучающую выборку, и новые данные. В этом случае алгоритм необходимо усложнять.\n",
    "\n",
    "В случае переобучения, данные из обучающей выборки будут описываться хорошо, а новые данные плохо. Выявить переобучение, используя только обучающую выборку, невозможно, поскольку и хорошо обученный, и переобученный алгоритмы будут хорошо ее описывать. Необходимо использовать дополнительные данные.\n",
    "\n",
    "Существуют несколько подходов к выявлению переобучения:\n",
    "* Отложенная выборка. Часть данных из обучающей выборки не участвуют в обучении, чтобы позже проверять на ней обученный алгоритм.\n",
    "* Кросс-валидация, несколько усложненный метод отложенной выборки.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Регуляризация\n",
    "**Регуляризация** - способ борьбы с переобучением, используемый в линейных моделях.\n",
    "\n",
    "### «Симптомы» переобучения. Мультиколлинеарность.\n",
    "\n",
    "Мерой сложности, то есть «симптомом» переобученности модели, являются большие веса при признаках.\n",
    "\n",
    "Например, в предыдущем разделе при обучении модели\n",
    "$$a(x) = w0 + w_1x + w_2x^2 + \\ldots + w_9x^9$$\n",
    "веса оказывались огромными:\n",
    "$$a(x) = 0.5 + 12458922x + 43983740x^2 + \\ldots + 2740x^9$$\n",
    "\n",
    "Другая ситуация, в которой можно встретиться с переобучением — мультиколлинеарность. Так называется проблема, при которой признаки в выборке являются линейно зависимыми. Другими словами, существуют коэффициенты $\\alpha_1; \\ldots; \\alpha_d$ такие, что для любого объекта $x_i$ из выборки выполняется:\n",
    "$$\\alpha_1 x^1_i + \\ldots + \\alpha_d x^d_i = 0$$\n",
    "Более компактно последнее выражение можно переписать в виде: $\\langle \\alpha, x_i \\rangle = 0$.\n",
    "\n",
    "Допустим, было найдено решение задачи оптимизации: \n",
    "$$ w^{*} = \\arg\\min_{w} \\frac{1}{l}\\sum_{i=1}^{l}(\\langle w, x_i \\rangle - y_i )^2$$\n",
    "Другой вектор весов, полученный сдвигом в направлении вектора $\\alpha$:\n",
    "$$w_1 = w^{*} + t\\alpha$$\n",
    "так как для элементов $x$ выборки выполняется:\n",
    "$$\\langle w^{*} + t\\alpha, x \\rangle = \\langle w^{*}, x \\rangle + t\\langle w^{*}, \\alpha \\rangle =  \\langle w^{*}, x \\rangle$$\n",
    "также будет являться решением задачи оптимизации. Другими словами, он будет также хорошо описывать данные в выборке, как и исходный алгоритм. Фактически, решениями задачи оптимизации являются бесконечное множество алгоритмов, но многие из них имеют большие веса, и далеко не все обладают хорошей обобщающей способностью. Поэтому здесь тоже легко столкнуться с переобучением.\n",
    "\n",
    "#### Иллюстрация роста весов в линейной модели при переобучении\n",
    "Попытаемся понять на примере влияние сложности модели на значение весовых коэффициентов. \n",
    "В качестве примера, произведем симуляцию кривой синусоиды (между 60 и 300 градусами) и добавим некоторый случайным шум.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x143f4c1b128>]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+gAAAM1CAYAAADjA9sVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiRJDfgvZhd9DU8itvIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x143f47ba518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Необходимое импортирование модулей\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import rcParams\n",
    "\n",
    "#Задаем размер графика\n",
    "rcParams['figure.figsize'] = 12, 10\n",
    "\n",
    "x = np.array([i*np.pi/180 for i in range(60,300,4)])\n",
    "# Определяем массив со значениями углов от 60 до 300 градусов в радианах\n",
    "\n",
    "np.random.seed(10)  \n",
    "#Генератор случайных чисел\n",
    "\n",
    "\n",
    "y = np.sin(x) + np.random.normal(0,0.15,len(x))\n",
    "data = pd.DataFrame(np.column_stack([x,y]),columns=['x','y']) # Для удобства используется pandas\n",
    "\n",
    "plt.plot(data['x'],data['y'],'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно заметить, это напоминает синусоиду, но не в точности (из-за присутствия шума). Мы будем использовать это как пример для тестирования различных сценариев.\n",
    "\n",
    "Попытаемся оценить синусоиду с использованием полиномиальной регрессии со степенями $x$ от 1 до 15. К таблице добавим столбец для каждой степени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>x_10</th>\n",
       "      <th>x_11</th>\n",
       "      <th>x_12</th>\n",
       "      <th>x_13</th>\n",
       "      <th>x_14</th>\n",
       "      <th>x_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.047198</td>\n",
       "      <td>1.065763</td>\n",
       "      <td>1.096623</td>\n",
       "      <td>1.148381</td>\n",
       "      <td>1.202581</td>\n",
       "      <td>1.259340</td>\n",
       "      <td>1.318778</td>\n",
       "      <td>1.381021</td>\n",
       "      <td>1.446202</td>\n",
       "      <td>1.514459</td>\n",
       "      <td>1.585938</td>\n",
       "      <td>1.660790</td>\n",
       "      <td>1.739176</td>\n",
       "      <td>1.821260</td>\n",
       "      <td>1.907219</td>\n",
       "      <td>1.997235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.117011</td>\n",
       "      <td>1.006086</td>\n",
       "      <td>1.247713</td>\n",
       "      <td>1.393709</td>\n",
       "      <td>1.556788</td>\n",
       "      <td>1.738948</td>\n",
       "      <td>1.942424</td>\n",
       "      <td>2.169709</td>\n",
       "      <td>2.423588</td>\n",
       "      <td>2.707173</td>\n",
       "      <td>3.023942</td>\n",
       "      <td>3.377775</td>\n",
       "      <td>3.773011</td>\n",
       "      <td>4.214494</td>\n",
       "      <td>4.707635</td>\n",
       "      <td>5.258479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.186824</td>\n",
       "      <td>0.695374</td>\n",
       "      <td>1.408551</td>\n",
       "      <td>1.671702</td>\n",
       "      <td>1.984016</td>\n",
       "      <td>2.354677</td>\n",
       "      <td>2.794587</td>\n",
       "      <td>3.316683</td>\n",
       "      <td>3.936319</td>\n",
       "      <td>4.671717</td>\n",
       "      <td>5.544505</td>\n",
       "      <td>6.580351</td>\n",
       "      <td>7.809718</td>\n",
       "      <td>9.268760</td>\n",
       "      <td>11.000386</td>\n",
       "      <td>13.055521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.256637</td>\n",
       "      <td>0.949799</td>\n",
       "      <td>1.579137</td>\n",
       "      <td>1.984402</td>\n",
       "      <td>2.493673</td>\n",
       "      <td>3.133642</td>\n",
       "      <td>3.937850</td>\n",
       "      <td>4.948448</td>\n",
       "      <td>6.218404</td>\n",
       "      <td>7.814277</td>\n",
       "      <td>9.819710</td>\n",
       "      <td>12.339811</td>\n",
       "      <td>15.506664</td>\n",
       "      <td>19.486248</td>\n",
       "      <td>24.487142</td>\n",
       "      <td>30.771450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.326450</td>\n",
       "      <td>1.063496</td>\n",
       "      <td>1.759470</td>\n",
       "      <td>2.333850</td>\n",
       "      <td>3.095735</td>\n",
       "      <td>4.106339</td>\n",
       "      <td>5.446854</td>\n",
       "      <td>7.224981</td>\n",
       "      <td>9.583578</td>\n",
       "      <td>12.712139</td>\n",
       "      <td>16.862020</td>\n",
       "      <td>22.366630</td>\n",
       "      <td>29.668222</td>\n",
       "      <td>39.353420</td>\n",
       "      <td>52.200353</td>\n",
       "      <td>69.241170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y       x_2       x_3       x_4       x_5       x_6  \\\n",
       "0  1.047198  1.065763  1.096623  1.148381  1.202581  1.259340  1.318778   \n",
       "1  1.117011  1.006086  1.247713  1.393709  1.556788  1.738948  1.942424   \n",
       "2  1.186824  0.695374  1.408551  1.671702  1.984016  2.354677  2.794587   \n",
       "3  1.256637  0.949799  1.579137  1.984402  2.493673  3.133642  3.937850   \n",
       "4  1.326450  1.063496  1.759470  2.333850  3.095735  4.106339  5.446854   \n",
       "\n",
       "        x_7       x_8        x_9       x_10       x_11       x_12       x_13  \\\n",
       "0  1.381021  1.446202   1.514459   1.585938   1.660790   1.739176   1.821260   \n",
       "1  2.169709  2.423588   2.707173   3.023942   3.377775   3.773011   4.214494   \n",
       "2  3.316683  3.936319   4.671717   5.544505   6.580351   7.809718   9.268760   \n",
       "3  4.948448  6.218404   7.814277   9.819710  12.339811  15.506664  19.486248   \n",
       "4  7.224981  9.583578  12.712139  16.862020  22.366630  29.668222  39.353420   \n",
       "\n",
       "        x_14       x_15  \n",
       "0   1.907219   1.997235  \n",
       "1   4.707635   5.258479  \n",
       "2  11.000386  13.055521  \n",
       "3  24.487142  30.771450  \n",
       "4  52.200353  69.241170  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(2,16):  #power of 1 is already there\n",
    "    colname = 'x_%d'%i      #new var will be x_power\n",
    "    data[colname] = data['x']**i\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сейчас, мы имеем все 15 степеней, поэтому можем сделать 15 различных линейных регрессионных моделей с каждой моделью, содержащей переменные со степенями $x$ от $1$ до конкретного числа модели. Например, множество атрибутов для модели $8$ будет следующим: $\\left\\{ x, x_2, x_3, … ,x_8 \\right\\} $.\n",
    "\n",
    "Для начала, определим общую функцию, которая принимает на вход требуемую максимальную степень $x$ (например, $p$) и возвращает список, содержащий: \n",
    "[ RSS модели, $w_0$, $w_1$, $w_2$, \\ldots, $w_p$ ].\n",
    "\n",
    "RSS - сумма квадратов остатков между предсказанным и фактическим значениями в тренировочной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def linear_regression(data, power, models_to_plot):\n",
    "    #initialize predictors:\n",
    "    predictors=['x']\n",
    "    if power>=2:\n",
    "        predictors.extend(['x_%d'%i for i in range(2,power+1)])\n",
    "    \n",
    "    #Fit the model\n",
    "    linreg = LinearRegression(normalize=True)\n",
    "    linreg.fit(data[predictors],data['y'])\n",
    "    y_pred = linreg.predict(data[predictors])\n",
    "    \n",
    "    #Check if a plot is to be made for the entered power\n",
    "    if power in models_to_plot:\n",
    "        plt.subplot(models_to_plot[power])\n",
    "        plt.tight_layout()\n",
    "        plt.plot(data['x'],y_pred)\n",
    "        plt.plot(data['x'],data['y'],'.')\n",
    "        plt.title('Plot for power: %d'%power)\n",
    "    \n",
    "    #Return the result in pre-defined format\n",
    "    rss = sum((y_pred-data['y'])**2)\n",
    "    ret = [rss]\n",
    "    ret.extend([linreg.intercept_])\n",
    "    ret.extend(linreg.coef_)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта функция не строит модели для всех степеней, а возвращает RSS и коэффициенты для всех моделей.\n",
    "Итак, мы сделали 15 моделей и сравнили результаты. Для легкости анализа, сохраним все результаты в виде Pandas DataFrame и построим 6 моделей.\n",
    "\n",
    "Мы ожидаем, что модели с увеличением сложности всё лучше адаптируются к данным и в результате получается всё меньшее значение RSS. Это можно увидеть на графиках, построенных для 6 моделей.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAPeCAYAAADd/6nHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiRJkiRJKjibUpIkSZIkSSq4/wcU2OWNme8VUwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x143f3765ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Initialize a dataframe to store the results:\n",
    "col = ['rss','intercept'] + ['coef_x_%d'%i for i in range(1,16)]\n",
    "ind = ['model_pow_%d'%i for i in range(1,16)]\n",
    "coef_matrix_simple = pd.DataFrame(index=ind, columns=col)\n",
    "\n",
    "#Define the powers for which a plot is required:\n",
    "models_to_plot = {1:231,3:232,6:233,9:234,12:235,15:236}\n",
    "\n",
    "#Iterate through all powers and assimilate results\n",
    "for i in range(1,16):\n",
    "    coef_matrix_simple.iloc[i-1,0:i+2] = linear_regression(data, power=i, models_to_plot=models_to_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, с увеличением сложности модели она стремится адаптироваться даже к малым отклонениям в тренировочной выборке. Это ведет к **переобучению**.\n",
    "Но вернемся к рассмотрению влияния на величину весовых коэффициентов. Рассмотрим таблицу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rss</th>\n",
       "      <th>intercept</th>\n",
       "      <th>coef_x_1</th>\n",
       "      <th>coef_x_2</th>\n",
       "      <th>coef_x_3</th>\n",
       "      <th>coef_x_4</th>\n",
       "      <th>coef_x_5</th>\n",
       "      <th>coef_x_6</th>\n",
       "      <th>coef_x_7</th>\n",
       "      <th>coef_x_8</th>\n",
       "      <th>coef_x_9</th>\n",
       "      <th>coef_x_10</th>\n",
       "      <th>coef_x_11</th>\n",
       "      <th>coef_x_12</th>\n",
       "      <th>coef_x_13</th>\n",
       "      <th>coef_x_14</th>\n",
       "      <th>coef_x_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_pow_1</th>\n",
       "      <td>3.3</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pow_2</th>\n",
       "      <td>3.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pow_3</th>\n",
       "      <td>1.1</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>0.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pow_4</th>\n",
       "      <td>1.1</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pow_5</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-5.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pow_6</th>\n",
       "      <td>0.99</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-9.7</td>\n",
       "      <td>5.2</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pow_7</th>\n",
       "      <td>0.93</td>\n",
       "      <td>19</td>\n",
       "      <td>-56</td>\n",
       "      <td>69</td>\n",
       "      <td>-45</td>\n",
       "      <td>17</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pow_8</th>\n",
       "      <td>0.92</td>\n",
       "      <td>43</td>\n",
       "      <td>-1.4e+02</td>\n",
       "      <td>1.8e+02</td>\n",
       "      <td>-1.3e+02</td>\n",
       "      <td>58</td>\n",
       "      <td>-15</td>\n",
       "      <td>2.4</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pow_9</th>\n",
       "      <td>0.87</td>\n",
       "      <td>1.7e+02</td>\n",
       "      <td>-6.1e+02</td>\n",
       "      <td>9.6e+02</td>\n",
       "      <td>-8.5e+02</td>\n",
       "      <td>4.6e+02</td>\n",
       "      <td>-1.6e+02</td>\n",
       "      <td>37</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pow_10</th>\n",
       "      <td>0.87</td>\n",
       "      <td>1.4e+02</td>\n",
       "      <td>-4.9e+02</td>\n",
       "      <td>7.3e+02</td>\n",
       "      <td>-6e+02</td>\n",
       "      <td>2.9e+02</td>\n",
       "      <td>-87</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.0013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pow_11</th>\n",
       "      <td>0.87</td>\n",
       "      <td>-75</td>\n",
       "      <td>5.1e+02</td>\n",
       "      <td>-1.3e+03</td>\n",
       "      <td>1.9e+03</td>\n",
       "      <td>-1.6e+03</td>\n",
       "      <td>9.1e+02</td>\n",
       "      <td>-3.5e+02</td>\n",
       "      <td>91</td>\n",
       "      <td>-16</td>\n",
       "      <td>1.8</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pow_12</th>\n",
       "      <td>0.87</td>\n",
       "      <td>-3.4e+02</td>\n",
       "      <td>1.9e+03</td>\n",
       "      <td>-4.4e+03</td>\n",
       "      <td>6e+03</td>\n",
       "      <td>-5.2e+03</td>\n",
       "      <td>3.1e+03</td>\n",
       "      <td>-1.3e+03</td>\n",
       "      <td>3.8e+02</td>\n",
       "      <td>-80</td>\n",
       "      <td>12</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>0.062</td>\n",
       "      <td>-0.0016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pow_13</th>\n",
       "      <td>0.86</td>\n",
       "      <td>3.2e+03</td>\n",
       "      <td>-1.8e+04</td>\n",
       "      <td>4.5e+04</td>\n",
       "      <td>-6.7e+04</td>\n",
       "      <td>6.6e+04</td>\n",
       "      <td>-4.6e+04</td>\n",
       "      <td>2.3e+04</td>\n",
       "      <td>-8.5e+03</td>\n",
       "      <td>2.3e+03</td>\n",
       "      <td>-4.5e+02</td>\n",
       "      <td>62</td>\n",
       "      <td>-5.7</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-0.0078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pow_14</th>\n",
       "      <td>0.79</td>\n",
       "      <td>2.4e+04</td>\n",
       "      <td>-1.4e+05</td>\n",
       "      <td>3.8e+05</td>\n",
       "      <td>-6.1e+05</td>\n",
       "      <td>6.6e+05</td>\n",
       "      <td>-5e+05</td>\n",
       "      <td>2.8e+05</td>\n",
       "      <td>-1.2e+05</td>\n",
       "      <td>3.7e+04</td>\n",
       "      <td>-8.5e+03</td>\n",
       "      <td>1.5e+03</td>\n",
       "      <td>-1.8e+02</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>0.017</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pow_15</th>\n",
       "      <td>0.7</td>\n",
       "      <td>-3.6e+04</td>\n",
       "      <td>2.4e+05</td>\n",
       "      <td>-7.5e+05</td>\n",
       "      <td>1.4e+06</td>\n",
       "      <td>-1.7e+06</td>\n",
       "      <td>1.5e+06</td>\n",
       "      <td>-1e+06</td>\n",
       "      <td>5e+05</td>\n",
       "      <td>-1.9e+05</td>\n",
       "      <td>5.4e+04</td>\n",
       "      <td>-1.2e+04</td>\n",
       "      <td>1.9e+03</td>\n",
       "      <td>-2.2e+02</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              rss intercept coef_x_1 coef_x_2 coef_x_3 coef_x_4 coef_x_5  \\\n",
       "model_pow_1   3.3         2    -0.62      NaN      NaN      NaN      NaN   \n",
       "model_pow_2   3.3       1.9    -0.58   -0.006      NaN      NaN      NaN   \n",
       "model_pow_3   1.1      -1.1        3     -1.3     0.14      NaN      NaN   \n",
       "model_pow_4   1.1     -0.27      1.7    -0.53   -0.036    0.014      NaN   \n",
       "model_pow_5     1         3     -5.1      4.7     -1.9     0.33   -0.021   \n",
       "model_pow_6  0.99      -2.8      9.5     -9.7      5.2     -1.6     0.23   \n",
       "model_pow_7  0.93        19      -56       69      -45       17     -3.5   \n",
       "model_pow_8  0.92        43 -1.4e+02  1.8e+02 -1.3e+02       58      -15   \n",
       "model_pow_9  0.87   1.7e+02 -6.1e+02  9.6e+02 -8.5e+02  4.6e+02 -1.6e+02   \n",
       "model_pow_10 0.87   1.4e+02 -4.9e+02  7.3e+02   -6e+02  2.9e+02      -87   \n",
       "model_pow_11 0.87       -75  5.1e+02 -1.3e+03  1.9e+03 -1.6e+03  9.1e+02   \n",
       "model_pow_12 0.87  -3.4e+02  1.9e+03 -4.4e+03    6e+03 -5.2e+03  3.1e+03   \n",
       "model_pow_13 0.86   3.2e+03 -1.8e+04  4.5e+04 -6.7e+04  6.6e+04 -4.6e+04   \n",
       "model_pow_14 0.79   2.4e+04 -1.4e+05  3.8e+05 -6.1e+05  6.6e+05   -5e+05   \n",
       "model_pow_15  0.7  -3.6e+04  2.4e+05 -7.5e+05  1.4e+06 -1.7e+06  1.5e+06   \n",
       "\n",
       "             coef_x_6 coef_x_7 coef_x_8 coef_x_9 coef_x_10 coef_x_11  \\\n",
       "model_pow_1       NaN      NaN      NaN      NaN       NaN       NaN   \n",
       "model_pow_2       NaN      NaN      NaN      NaN       NaN       NaN   \n",
       "model_pow_3       NaN      NaN      NaN      NaN       NaN       NaN   \n",
       "model_pow_4       NaN      NaN      NaN      NaN       NaN       NaN   \n",
       "model_pow_5       NaN      NaN      NaN      NaN       NaN       NaN   \n",
       "model_pow_6    -0.014      NaN      NaN      NaN       NaN       NaN   \n",
       "model_pow_7       0.4   -0.019      NaN      NaN       NaN       NaN   \n",
       "model_pow_8       2.4    -0.21   0.0077      NaN       NaN       NaN   \n",
       "model_pow_9        37     -5.2     0.42   -0.015       NaN       NaN   \n",
       "model_pow_10       15    -0.81    -0.14    0.026   -0.0013       NaN   \n",
       "model_pow_11 -3.5e+02       91      -16      1.8     -0.12    0.0034   \n",
       "model_pow_12 -1.3e+03  3.8e+02      -80       12      -1.1     0.062   \n",
       "model_pow_13  2.3e+04 -8.5e+03  2.3e+03 -4.5e+02        62      -5.7   \n",
       "model_pow_14  2.8e+05 -1.2e+05  3.7e+04 -8.5e+03   1.5e+03  -1.8e+02   \n",
       "model_pow_15   -1e+06    5e+05 -1.9e+05  5.4e+04  -1.2e+04   1.9e+03   \n",
       "\n",
       "             coef_x_12 coef_x_13 coef_x_14 coef_x_15  \n",
       "model_pow_1        NaN       NaN       NaN       NaN  \n",
       "model_pow_2        NaN       NaN       NaN       NaN  \n",
       "model_pow_3        NaN       NaN       NaN       NaN  \n",
       "model_pow_4        NaN       NaN       NaN       NaN  \n",
       "model_pow_5        NaN       NaN       NaN       NaN  \n",
       "model_pow_6        NaN       NaN       NaN       NaN  \n",
       "model_pow_7        NaN       NaN       NaN       NaN  \n",
       "model_pow_8        NaN       NaN       NaN       NaN  \n",
       "model_pow_9        NaN       NaN       NaN       NaN  \n",
       "model_pow_10       NaN       NaN       NaN       NaN  \n",
       "model_pow_11       NaN       NaN       NaN       NaN  \n",
       "model_pow_12   -0.0016       NaN       NaN       NaN  \n",
       "model_pow_13      0.31   -0.0078       NaN       NaN  \n",
       "model_pow_14        15     -0.73     0.017       NaN  \n",
       "model_pow_15  -2.2e+02        17     -0.81     0.018  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set the display format to be scientific for ease of analysis\n",
    "pd.options.display.float_format = '{:,.2g}'.format\n",
    "coef_matrix_simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ясно видно, что величина весовых коэффициентов **увеличивается с ростом сложности модели**. \n",
    "\n",
    "Итак, интуитивно мы пришли к пониманию, что ограничение величины коэффициентов может быть хорошей идеей, чтобы уменьшить сложности модели.\n",
    "\n",
    "Что означает большая величина коэффициентов?\n",
    "Это означает, что мы обращаем большое внимание на данный атрибут, т.е. этот атрибут является хорошим предиктором для целевой переменной. Когда он становится слишком большим, алгоритм начинает моделировать слишком сложные отношения для оценки данных и это заканчивается переобучением для конкретной тренировочной выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Регуляризация\n",
    "\n",
    "Выше было продемонстрировано, что если веса в линейной модели большие, существует высокий риск переобучения. Чтобы бороться с этим, минимизируется уже не выражение для функционала ошибки $J(w)$, а новый функционал, получаемый прибавлением регуляризатора. Самый простой регуляризатор — квадратичный регуляризатор:\n",
    "$$ \\left\\Vert w \\right\\Vert^2 = \\sum_{j=1}^{d} w_j^2$$\n",
    "В этом случае имеет место следующая задача оптимизации:\n",
    "$$ J(w) + \\lambda \\left\\Vert w \\right\\Vert^2 \\to \\min$$\n",
    "Таким образом, при обучении будет учитываться также то, что не следует слишком сильно увеличивать веса признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Коэффициент регуляризации\n",
    "Введенный выше коэффициент $\\lambda$, который стоит перед регуляризатором, называется коэффициентом регуляризации. Чем больше $\\lambda$, тем ниже сложность модели. Например, при очень больших его значениях оптимально просто занулить все веса. В то же время при слишком низких значениях $\\lambda$ высок риск переобучения, то есть модель становится слишком сложной.\n",
    "\n",
    "Поэтому нужно найти некоторое оптимальное значение $\\lambda$, достаточно большое, чтобы не допустить переобучения, и не очень большое, чтобы уловить закономерности в данных. Обычно $\\lambda$ подбирается на кроссвалидации, о которой пойдет речь в ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Смысл регуляризации\n",
    "\n",
    "Чтобы понять смысл регуляризации, вместо задачи оптимизации с квадратичным оптимизатором нагляднее рассмотреть задачу условной оптимизации:\n",
    "$$\\begin{cases} J(w) \\to \\min_w  \\\\  \\left\\Vert w \\right\\Vert^2 \\leq C \\end{cases}$$\n",
    "\n",
    "Добавление регуляризатора вводит требование, чтобы решение задачи минимизации искалось в некоторой круглой области с центром в нуле.\n",
    "![](OverfittingImg\\img\\Overfitting\\img6.png)\n",
    "<h4 align=\"center\">Рис. 6:  Геометрический смысл условной регуляризации. Красная точка — настоящий оптимум функции, красные линии — линии уровня функции, черная точка — оптимум функции при введенном ограничении.</h4> \n",
    "\n",
    "Таким образом, решение задачи с регуляризатором не будет характеризоваться слишком большими значениями весовых коэффициентов.\n",
    "\n",
    "\n",
    "### Виды регуляризаторов\n",
    "Рассмотренный выше квадратичный регуляризатор (L2-регуляризатор) является гладким и выпуклым, что позволяет использовать градиентный спуск.\n",
    "\n",
    "Также существует $L_1$-регуляризатор:\n",
    "$$\\left\\Vert w \\right\\Vert_1 = \\sum_{j=1}^{d} \\left| w_j \\right|$$\n",
    "который представляет собой $L_1$-норму вектора весов. Он уже не является гладким, а также обладает интерес ным свойством. Если применять такой регуляризатор, некоторые веса оказываются равными нулю. Другими словами, такой регуляризатор производит отбор признаков и позволяет использовать в модели не все признаки, а только самые важные из них.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка качества алгоритмов. Кросс-валидация\n",
    "Поговорим об оценке качества алгоритмов и о том, как понять, как поведет себя алгоритм на новых данных.\n",
    "\n",
    "### Выявление переобучения\n",
    "Уже было сказано, что переобучение сложно выявить, используя только обучающую выборку: и хороший, и переобученный алгоритмы будут показывать хорошее качество на объектах обучающей выборки. Рассмотренные ранее меры переобученности (значения регуляризаторов), безусловно, можно применять, но они не дают ответа на вопрос, насколько хорошо алгоритм поведет себя на новых данных, то есть какая у него будет доля ошибок на новых данных.\n",
    "\n",
    "### Отложенная выборка\n",
    "Самый простой способ оценить качество алгоритма — использование отложенной выборки. В этом случае следует разбить выборку на две части: первая из двух частей будет использоваться для обучения алгоритма, а вторая, тестовая выборка, — для оценки его качества, в том числе для нахождения доли ошибок в задаче классификации, MSE (среднеквадратичной ошибки) в задаче регрессии и других мер качества в зависимости от специфики задачи.\n",
    "\n",
    "Естественный вопрос — о том, в какой пропорции производить разбиение. Если взять тестовую выборку слишком маленькой, оценка качества будет ненадежной, хотя обучающая выборка будет почти совпадать с полной выборкой. В противоположенном случае, если отложенная часть будет большой, оценка качества будет надежной, но низкое качество алгоритма может свидетельствовать о недостаточном объёме первой, обучающей, части выборки. Обычно выборку разбивают в соотношениях $70/30$, $80/20$ или $0.632/0.368$.\n",
    "\n",
    "Преимуществом отложенной выборки является то, что обучать алгоритм приходится всего лишь один раз, но при этом результат сильно зависит от того, как было произведено разбиение.\n",
    "\n",
    "Например, оценивается стоимость жилья по некоторым признакам. И есть особая категория жилья, например двухэтажные квартиры. И если окажется, что все двухэтажные квартиры, которых немного, попали в отложенную выборку, то после обучения алгоритм будет давать на них очень плохое качество, поскольку в обучающей выборке таких объектов не было.\n",
    "\n",
    "Чтобы решить эту проблему, можно использовать следующий подход: построить $n$ различных разбиений выборки на $2$ части, для каждого разбиения найти оценку качества, а в качестве итоговой оценки качества работы алгоритма использовать усредненное по всем разбиениям значение. Но и в данном случае, поскольку разбиения строятся случайно, нет никаких гарантий, что особый объект хотя бы раз попадет на обучение.\n",
    "\n",
    "### Кросс-валидация\n",
    "Более системный подход — кросс валидация. В этом случае выборка делится на $k$ блоков примерно одинакового размера. Далее по очереди каждый из этих блоков используется в качестве тестового, а все остальные — в качестве обучающей выборки.\\\n",
    "\n",
    "После того, как каждый блок побывает в качестве тестового, будут получены $k$ показателей качества. В результате усреднения получается оценка качества по кросс-валидации.\n",
    "\n",
    "При этом встает вопрос, какое число блоков использовать. Если блоков мало, получаются надежные, но смещенные оценки. В случае большого числа блоков оценки, наоборот, получаются ненадежными (большой разброс оценок), но несмещенными.\n",
    "\n",
    "Нет конкретных рекомендаций относительно выбора $k$. Обычно выбирают $k = 3; 5; 10$. Чем больше $k$, тем больше раз приходится обучать алгоритм. Поэтому на больших выборках следует выбирать небольшие значения $k$, так как даже при удалении $1/3$ выборки (а она большая) оставшихся данных будет достаточно для обучения.\n",
    "\n",
    "### Совет: перемешивайте данные в выборке\n",
    "Часто данные в файле записаны в отсортированном виде по какого-нибудь признаку. Поэтому всегда следует перемешивать выборку прежде, чем производить кросс-валидацию. В ином случае алгоритм будет показывать плохое качество и причина этого будет не так очевидна.\n",
    "\n",
    "При этом есть задачи, в которых выборку нельзя перемешивать. Это задачи предсказания будущего,\n",
    "например предсказание погоды на следующий день. В этом случае нужно особо следить за тем, как происходит\n",
    "деление выборки.\n",
    "\n",
    "## Выбор гиперпараметров и сравнение алгоритмов\n",
    "\n",
    "### Гиперпараметры\n",
    "Гиперпараметрами называются такие параметры алгоритмов, которые не могут быть получены из обучающей выборки при обучении, поэтому их надо подбирать путем многократного обучения алгоритма. Примерами гиперпараметров являются:\n",
    "• Параметр регуляризации $\\alpha$ (при использовании регуляризатора)\n",
    "• Степень полинома в задаче регрессии с семейством алгоритмов, заданным множеством полиномов определенной степени.\n",
    "\n",
    "### Сравнение разных алгоритмов\n",
    "Более общая задача — сравнение разных алгоритмов:\n",
    "* обученных с разными значениями гиперпараметров;\n",
    "* использующих различный способ регуляризации;\n",
    "* настроенных с использованием разного функционала ошибки, например среднеквадратичной ошибки и средней абсолютной ошибки;\n",
    "* которые принадлежат разным классам алгоритмов.\n",
    "При сравнении алгоритмов можно использовать как отложенную выборку, так и кросс-валидацию, но при этом следует соблюдать осторожность.\n",
    "\n",
    "Действительно, пусть 1000 алгоритмов сравниваются по качеству на отложенной выборке. Каждый из 1000 алгоритмов, обученных на обучающей выборке, тестируется на отложенной, и в результате выбирается лучший. Фактически на этом шаге отложенная выборка также становится своего рода обучающей, и возникает проблема переобучения: из большого числа алгоритмов выбирается тот, который лучше всего ведет себя на отложенной выборке, лучше подогнан под нее.\n",
    "\n",
    "### Улучшенная схема сравнения алгоритмов\n",
    "Чтобы бороться с этим, следует использовать несколько усовершенствованную схему оценивания качества алгоритмов, а именно все данные нужно будет делить на 3 части (в случае использования отложенной выборки): обучение, валидация и контроль. Каждый из тысячи алгоритмов будет обучен на обучающей выборке, а его качество будет измерено на валидационной. Алгоритм с наилучшим качеством будет проверен на тестовой выборке, чтобы исключить переобучение и проверить алгоритм на адекватность. По сути именно тестовая выборка будет играть роль новых данных.\n",
    "\n",
    "Если предпочтительно использовать кросс-валидацию, то данные следует разбить на 2 части. Первая из них будет использоваться для обучения алгоритмов и оценки качества с помощью кросс-валидации, после чего лучший алгоритм будет проверен на адекватность на контрольной выборке.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Регрессия со штрафом, или регуляризованная регрессия в scikit-learn\n",
    "\n",
    "Итак, еще раз затронем важный класс регресионных моделей - регрессия со штрафом, или **регуляризованная регрессия**.\n",
    "\n",
    "При обычной регрессии возвращается наилучшая аппроксимация обучающих данных, что может привести к переобучению. Штрафование ознгачает, что мы включаем штраф за чрезмерное доверие к параметрическим данным. Иначе говоря, мы соглашаемся на худшую аппроксимацию ради более простой модели.\n",
    "\n",
    "Можно взглянуть иначе - считать, что по умолчанию нет никакой связи между входными переменными и выходным прогнозом. Получая данные, мы изменяем это мнение, а добавление штрафа означает, что требуется больше данных, чтобы убедить нас в наличии сильной связи.\n",
    "\n",
    "### Штрафы $L_1$ и $L_2$\n",
    "\n",
    "В общем случае, мы имеем матрицу $X$ обучающих данных. Задача состоит в том, чтобы найти вектор весов $w^{*}$. В случае регрессии методов наименьших квадратов он выражается сл. формулой:\n",
    "$$w^{*} = \\arg\\min_w \\left| y - Xw\\right|^{2}$$\n",
    "\n",
    "То есть требуется найти вектор $w$, который обращает в минимум квадрат расстояния до вектора $y$. \n",
    "Добавление штрафа, или регуляризация означает, что мы хотим не только найти лучую аппроксимацию, но и принимаем во внимание значение вектора.\n",
    "Существует два основных штрафа, применяемые в случае регрессии:\n",
    "* $L_1$ - к регрессии добавляется сумма абсолютных значений коэффициентов. Тогда имеем формулу: $$w^{*} = \\arg\\min_w \\left| y - Xw\\right|^{2} + \\lambda \\sum_{i}\\left|w_i\\right| $$\n",
    "* $L_2$ - к регрессии добавляется сумма квадратов коэффициентов. Формула: $$w^{*} = \\arg\\min_w \\left| y - Xw\\right|^{2} + \\lambda\\sum_{i}w_i^2 $$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$L_1$-регуляризованная регрессия называется также **Lasso-регрессией**, а $L_2$-регуляризованная регрессия называется **гребневой регрессией** (или **Ridge-регрессией**).\n",
    "\n",
    "На первый взгляд, различие между $L_1$ и $L_2$ несущественное: штраф составляет не сумму абсолютных величин коэффициентов, а сумму их квадратов. Однако результаты могут отличаться довольно сильно.\n",
    "\n",
    "Как Lasso, так и гребневая регрессия дают меньшие (по абсолютной величине) значения коэффициентов. Однако у метода Lasso есть дополнительное преимущество - многие коэффициенты оказываются в точности равны нулю.\n",
    "Это означает, что в окончательной модели некоторые признаки не используются, т.е. модель получается **разреженной**. Часто это свойство весьма желательно, поскольку модель осуществляет не только регрессию, но и селекцию признаков.\n",
    "\n",
    "Штраф сопровождается весовым множителем $\\lambda$, контролирующим величину штрафа. Если значение $\\lambda$ близко к нулю, модель мало отличается от нерегуляризованной регрессии.\n",
    "\n",
    "Гребневая регрессия появилась раньше, потому что Lasso очень сложно рассчитать с помощью бумаги и карандаша. Но на современных компьютерах Lasso обсчитывается так же просто, как гребневая регрессия. При желании можно даже объединить два штрафа: сумму абсолютных величин и суммы квадратов, тогда получится уравнение следующего вида:\n",
    "\n",
    "$$w^{*} = \\arg\\min_w \\left| y - Xw\\right|^{2} + \\lambda_1 \\sum_{i}\\left|w_i\\right| + \\lambda_2\\sum_{i}w_i^2  $$\n",
    "\n",
    "Сочетание $L_1$ и $L_2$ регрессии называется **моделью эластичной сети (ElasticNet-Regression)**.\n",
    "\n",
    "\n",
    "#### Преимущества $L_1$ и $L_2$ регуляризации\n",
    "\n",
    "##### Преимущества $L_2$ регуляризации над $L_1$\n",
    "* Производная регуляризатора $L_2$ легко вычисляется. Поэтому, достаточно легко использовать методы, основанные на градиентном спуске;\n",
    "* $L_2$ регуляризация оптимизирует штраф математического ожидания (в то время как $L_1$ уменьшает медиану штрафа), что зачастую используется в качестве метрики производительности. Это особенно важно, если в исходных данных отсутствуют *выбросы (outliers)* и вы хотите сохранить общую ошибку достаточно малой;\n",
    "* Более вероятно то, что решение будет уникальным. Это связано с предыдущим пунктом: в то время как математическое ожидание (mean) является одной величиной, медиана может располагаться в интервале между двумя точками, и поэтому не быть уникальной.\n",
    "* В то время, как $L_1$ регуляризация даёт вам дает вам разряженный вектор коэффициентов (sparce coefficient vector), неразряженность (non-sparcity) вектора, порождаемого $L_2$ регуляризацией, может улучшить показатели качества классификации (поскольку, вы обрабатываете больше атрибутов, вместо их простого игнорирования);\n",
    "* $L_2$ ругляризация инварианта относительно операции поворота. Т.е. если в множестве содержится набор точек в пространстве и вы применяете поворот, вы получите те же самые результаты (т.е. дистанции между точками остаются теми же самыми);\n",
    "\n",
    "#### Преимущества $L_1$ регуляризации над $L_2$\n",
    "* $L_1$ регуляризация порождает разряженный вектор коэффициентов. Это означает, что $L_1$ регуляризация производил *отбор признаков (feature selection)* и вы можете удалить все атрибуты, с соответствующим весовым коэффициентом равным $0$. Редукция размерности бывает полезна почти во всех случаях;\n",
    "* $L_1$ регуляризация позволяет оптимизировать медиану. Поэтому, $L_1$ регуляризация нечувствительна к выбросам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Литература:**\n",
    "    \n",
    "* Building Machine Learning Systems with Python (Authors: Willi Richert, Luis Pedro Coelho)\n",
    "* An Introduction to Statistical Learning with Applications in R (Authors: Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani), http://www-bcf.usc.edu/~gareth/ISL/\n",
    "* https://www.analyticsvidhya.com/blog/2015/08/comprehensive-guide-regression\n",
    "* https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-ridge-lasso-regression-python/\n",
    "* http://stackoverflow.com/questions/32276391/feature-normalization-advantage-of-l2-normalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Машинное обучение без учителя (Unsupervised learning)\n",
    "\n",
    "## Взяла его ради примера с новостями и многоклассовой классификацией\n",
    "\n",
    "## Задача кластеризации\n",
    "\n",
    "### Обучение на размеченных данных\n",
    "\n",
    "В задачах обучения на размеченных данных, которые рассматривались в прошлом курсе, существовала некоторая целевая зависимость:\n",
    "$$x \\to y,$$\n",
    "где $y$ — значение прогнозируемой величины (в случае задачи регрессии) или метка класса (в случае задачи классификации). \n",
    "\n",
    "По обучающей выборке, которая состоит из множества объектов $x_1, \\ldots, x_l$ и ответов на них $y_1, \\ldots, y_l$ требовалось спрогнозировать ответы для объектов $x_{l+1}, \\ldots, x_{l+u}$ тестовой выборки. \n",
    "\n",
    "Фактически, ставилась задача приблизить целевую зависимость некоторой функцией $a(x)$:\n",
    "$$a(x) \\sim y.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача кластеризации\n",
    "\n",
    "В задаче кластеризации обучающая выборка  $x_1, \\ldots, x_l$  состоит только из объектов, но не содержит ответы на них, а также одновременно является и тестовой выборкой. Требуется расставить метки $y_1, \\ldots, y_l$ таким образом, чтобы похожие друг на друга объекты имели одинаковую метку, то есть разбить все объекты на некоторое количество групп.\n",
    "На рис. 1 приведен пример задачи кластеризации.\n",
    "\n",
    "![](img/clustering/img1.png)\n",
    "\n",
    "Задачу кластеризации также можно представить как восстановление отображения $x\\to y$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрики качества в задаче классификации\n",
    "\n",
    "Для измерения качества кластеризации требуется ввести так называемые метрики качества.\n",
    "\n",
    "Пусть $F_0$ - среднее расстояние между объектами в кластераз (должно быть как можно меньше), а $F_1$ - среднее расстояние между объектами из разных кластеров (должно быть как можно больше).\n",
    "\n",
    "Формально:\n",
    "\n",
    "$$F_0 = \\frac{\\sum_{i<j}\\lbrack y_i=y_j \\rbrack \\rho(x_i, x_j)}{\\sum_{i<j} \\lbrack y_i = y_j \\rbrack} \\to \\min $$\n",
    "\n",
    "$$F_1 = \\frac{\\sum_{i<j}\\lbrack y_i \\neq y_j \\rbrack \\rho(x_i, x_j)}{\\sum_{i<j} \\lbrack y_i \\neq y_j \\rbrack} \\to \\max $$\n",
    "\n",
    "Очевидно, что при оптимизации только одной из метрик $F_0$ или $F_1$ учтен будет всего лишь один из факторов. Учесть сразу оба можно, например, сл. образом:\n",
    "\n",
    "$$\\frac{F_0}{F_1} \\to \\min $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Примеры задач кластеризации\n",
    "\n",
    "В зависимости от специфики задачи и особенностей используемых в задаче данных задачи кластеризации могут сильно отличаться. Может, например, отличаться форма, размер и иерархия кластеров, а также тип задачи (основная или побочная) и тип классификации (жесткая или мягкая).\n",
    "\n",
    "#### Различные формы кластеров\n",
    "На рисунке 2 приведены примеры различных форм кластеров.\n",
    "\n",
    "![](img/clustering/img2.png)\n",
    "\n",
    "Как можно увидеть, кластеры могут иметь совершенно различную форму\n",
    "\n",
    "A) В простейшем случае кластеры представляют собой «сгустки точек» и могут быть легко выделены окружностью.\n",
    "\n",
    "B) Иногда кластеры принимают более сложную форму, но все также могут быть легко выделены.\n",
    "\n",
    "C) Возможен случай, когда между кластерами есть такие точки, которые сложно отнести к определенному кластеру.\n",
    "\n",
    "D) Кластеры могут представлять собой вытянутые ленты. В этом случае можно найти пару точек из разных кластеров, которые находятся ближе некоторой пары из одного кластера. Такие кластеры можно выделить, добавляя к строящемуся кластеру близжайшую точку.\n",
    "\n",
    "E) Кластеры могут плавно перетекать друг в друга. В этом случае описанная для предыдущего случая стратегия уже не работает.\n",
    "\n",
    "F) Кластеры могут быть образованы по некоторому закону, который все же не известен.\n",
    "\n",
    "G) Кластеры могут пересекаться. В этом случае достаточно сложно определить, к какому кластеру относятся некоторые объекты.\n",
    "\n",
    "Ну и **кластеров может вовсе не быть**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Иерархия и размер кластеров\n",
    "\n",
    "В практических задачах бывает нужно, чтобы внутри какого-нибудь большого кластера были кластеры меньшего размера. Например, в задаче кластеризации статей с сайта «habrahabr.ru», кластер «IT» может включать в себя кластер «Алгоритмы», внутри которого могут быть кластеры «Методы машинного обучения» и «Алгоритмы и структуры данных».\n",
    "\n",
    "![](img/clustering/img3.png)\n",
    "Также может различаться размер кластеров. Так, при кластеризации новостей по содержанию возможны следующие 3 варианта постановки задачи, которые отличаются размерами выделяемых кластеров:\n",
    "* В один и тот же кластер попадают новости на одну тему. Например, в первый кластер попадут все спортивные новости и так далее.\n",
    "* В один и тот же кластер попадают новости об одном и том же большом событии. Например, в один кластер попадут все новости про олимпиаду в городе Сочи.\n",
    "* В один и тот же кластер попадают тексты об одной и той же конкретной новости, например про открытие олимпиады в сочи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Основная или вспомогательная задачи\n",
    "В зависимости от цели задача кластеризации может быть:\n",
    "* **Основной**, когда полученная кластеризация не используется для решения какой–либо другой задачи.\n",
    "* **Вспомогательной**, если задача классификации является промежуточной при решении другой задачи.\n",
    "Рассмотренная выше задача кластеризации новостей является основной задачей.\n",
    "\n",
    "Задача сегментации целевой аудитории появляется, если для покупателей из разных групп требуется использовать разную маркетинговую кампанию.\n",
    "![](img/clustering/img4.png)\n",
    "\n",
    "Если для покупателей из разных групп требуется предлагать различный товар, то в этом случае задача кластеризации является вспомогательной по отношению к задаче рекомендации. Если задача сегментации решается для целей аналитики, то она, в свою очередь, будет основной.\n",
    "\n",
    "Другой пример вспомогательной задачи встречается при распознавании символов. Каждый символ может быть написан множеством различных способов, то есть иметь различные начертания: жирный, курсив и т.д.\n",
    "\n",
    "![](img/clustering/img5.png)\n",
    "\n",
    "В этом случае полезно сначала решить вспомогательную задачу кластеризации символов по их начертанию, а затем уже использовать полученную информацию для распознавания самих символов.\n",
    "\n",
    "#### Жёсткая или мягкая кластеризация\n",
    "\n",
    "В зависимости от того, может ли относиться объект сразу к нескольким кластерам бывает:\n",
    "* **Жесткая кластеризация**: объект может быть отнесен только к одному из кластеров.\n",
    "* **Мягкая кластеризация**: объект может быть отнесен к нескольким кластерам сразу (с некоторыми весами).\n",
    "\n",
    "Например, текст про применение кластеризации в области финансов в случае жесткой кластеризации по темам (финансы, анализ данных, кластеризация) будет отнесен к теме «кластеризация», а в случае мягкой кластеризации — ко всем трем темам с разными весами: к теме «кластеризация» с весом 0.5, к теме «анализ данных» с весом 0.3 и к теме «финансы» с весом 0.2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Типы кластеризации\n",
    "\n",
    "Итак, задача кластеризации субъективна, и это означает, что она может использоваться для достижения различных целей. \n",
    "Каждая метоика следует разным наборам правил для определения понятия \"похожести\" (similarity) среди точек из набора данных.\n",
    "\n",
    "На данный момент известно более ста алгоритмов кластеризации, но всего лишь несколько алгоритмов являются достаточно широко распространенными.\n",
    "\n",
    "**Connectivity models** Эти модели основываются на представлении, что точкие, расположенные ближе в пространстве данных, имеют больше сходства друг с другом, чем точки данных, лежащие дальше.\n",
    "Эти модели могут следовать двум подходам. Первый подход начинает с классификации всех точек в отдельные кластера, а затем их агрегации по мере уменьшения расстояния.\n",
    "Во втором подходе все точки классифицируются как один кластер, и затем он разбивается по мере увеличения расстояния. Кроме того, выбор функции расстояния **субъективен**. Эти модели легко интерпретировать, но их существенным недосттком является масштабируемость для обработки огромных наборов данных. Примерами этих моделей является алгоритмы иерархической кластеризации и его варианты.\n",
    "\n",
    "**Centroid models** Эти итеративные алгоритмы кластеризации используют представление о схожести как производной от близости точек к центроиду кластера. Примером алгоритма из этой категории является популярный алгоритм K-Means. В этих моделях требуется знаниче числа кластеров, на которые мы хотим разбить данные. А это значит, что достаточно важно иметь априорное знание о наборе данных. Эти модели работают итеративно, для нахождения некоторого локального минимума.\n",
    "\n",
    "**Distribution models**. Эти модели кластеризации основываются на понятии того, насколько вероятно то, что данные в кластере будут принадлежать тому же распределению (например, Гауссовскому (нормальному) распределению). Эти модели зачастую страдают от переобучения. Наверное, самым известным примером алгоритма этого класса является EM-алгоритм (Expectation-Maximization), использующий многомерные нормальные распределения.\n",
    "\n",
    "**Density Models**. Эти модели ищут пространства данныз для областей с *различной плотностью точек* в этом пространстве. Они \"изолируют\" области с разными областями плотности и назначают точкам внутри этих областей соответствующий кластер.\n",
    "Примерами алгоритмов этой модели являются алгоритмы DBSCAN и OPTICS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Идея двух простых алгоритмов\n",
    "\n",
    "Теперь рассмотрим \"абстрактно\" как работают два популярных алгоритма кластеризации.\n",
    "Начнем наше рассмотрение с алгоритма K-Means.\n",
    "\n",
    "### K-means clustering\n",
    "\n",
    "K-means представляет собой итеративный алгоритм кластеризации, целью которого является поиск локального максимума в каждой итерации. \n",
    "\n",
    "Этот алгоритм можно разбить на 5 шагов.\n",
    "\n",
    "1. Определение желаемого числа кластеров. Рассмотрим k=2 для 5 точек в двумерном пространстве.\n",
    "![](https://www.analyticsvidhya.com/wp-content/uploads/2016/11/clustering-2-293x300.png)\n",
    "\n",
    "\n",
    "2. Случайно выбираются $k$ случайных точек. Эти точки играют роль центров кластеров (центроидов кластеров).\n",
    "![](https://www.analyticsvidhya.com/wp-content/uploads/2016/11/clustering-3.png)\n",
    "\n",
    "3. Каждая точка относится к тому кластера, расстояние до центра которого минимально. \n",
    "![](https://www.analyticsvidhya.com/wp-content/uploads/2016/11/clustering-4.png)\n",
    "\n",
    "4. Повторно вычислить центроиды - среднее арифметическое всех точек, попавших в кластер \n",
    "![](https://www.analyticsvidhya.com/wp-content/uploads/2016/11/clustering-5.png)\n",
    "\n",
    "5. Шаги 3 и 4 повторяются пока не наступило условие для остановки. Мы будем повторять шаги 3 и 4 пока не достигнем глобального оптимума. Это может случиться когда точки не будут \"переключаться\" между разными кластерами за последовательные итерации. Это является сигналом к терминации алгоритма (если явно не указано иное).\n",
    "\n",
    "### Иерархическая кластеризация\n",
    "\n",
    "Иерархическая кластеризация является алгоритмом, который выстраивает иерархию кластеров. Этот алгоритм начинается с того, что каждой точке в пространстве данных назначается свой собственный кластер. Затем два ближайщих кластера объединяются в один кластер. В конце концов, алгоритм останавливается лишь тогда, когда остается только один кластер.\n",
    "\n",
    "Результаты иерархической кластеризации отображаются с использованием т.н. **дендрограммы**. Дендрограмма может быть интерпретирована как:\n",
    "![](https://www.analyticsvidhya.com/wp-content/uploads/2016/11/clustering-6.png)\n",
    "\n",
    "На рисунке, мы начинаем с 25 точек, и каждой назначается свой собственный кластер. Два ближайших кластера затем объединяются до тех пор, пока не останется единственный кластер (вверху). Высота на дендрограмме на которой два кластера объединются представляет дистанцию между двумя кластерами в пространстве данных.\n",
    "\n",
    "Глядя на дендрограмму мы можем принять решение о необходимом числе кластеров. Выбор числа кластеров является числом вертикальных линий в дендрограмме, когда мы проводим горизонтальную линию, которая пересекает максимальное расстояние по вертикали без пересечения кластеров.\n",
    "\n",
    "На примере ниже, оптимальным числом кластеров является 4, так как горизонтальная линия на дендрограмме ниже охватывает максимум вертикального расстояния AB.\n",
    "\n",
    "![](https://www.analyticsvidhya.com/wp-content/uploads/2016/11/clustering-7.png)\n",
    "\n",
    "Две важнейших вещи, которые нужно знать о иерархической кластеризации:\n",
    "* Алгоритм иерархической кластеризации реализует подход \"снизу вверх\". Также возможно следовать подходу \"сверху вниз\", который начинается с того, что все точки назначаются одному кластеру, и рекурсивно выполняется разбиение до тех пор, пока каждая точка не будет находится в собственном кластере.\n",
    "* Решение о объединении двух кластеров берется на ьазе близости этих кластеров. Есть несколько метрик для определения близости между двумя кластерами:\n",
    "* Евлидова метрика \n",
    "* Квадратичная Евклидова метрика\n",
    "* Манхеттенская метрика\n",
    "* Максимальное расстояние\n",
    "* Расстояние Махалонобиса\n",
    "\n",
    "## Разница между K-Means и иерархической кластеризации\n",
    "\n",
    "* Иерархическая кластеризация не может достаточно хорошо обрабатывать огромные наборы данных, в то время как K-Means успешно справляется с этой задачей. Это обусловлено временной сложностью алгоритма K-Means, которая является линейной, т.е. $O(n)$, в то время, как сложность иерархической кластеризации - квадратичная $O(n^2)$;\n",
    "* В кластеризации методом K-Means, поскольку мы начинаем со случайного выбора кластеров, результат, порожденный алгоритмом может отличаться при нескольких запусках. В этом недетерминированность алгоритма. В тоже время, результаты алгоритма иерархической кластеризации одни и те же;\n",
    "* K-Means достаточно хорошо работает, когда форма кластеров является гипер сферической (круг в двухмерном пространстве, сфера в трехмерном и т.д.);\n",
    "* Кластеризация K-Means требует априорного знания $K$, т.е. знания числа кластеров, на которые мы хотим разделить исходные данные. Но мы можем остановиться на любом числе кластеров, при интерпретации дендрограммы иерархической кластеризации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Знакомство с методами кластеризации\n",
    "\n",
    "Итак, кластеры могут иметь разный вид в зависимости от специфики задачи. Поэтому универсального алгоритма кластеризации не существует. При этом использование различных алгоритмов кластеризации в одной и той же задаче может давать совершенно разный ответ.\n",
    "\n",
    "Например, ниже показаны результаты метода k_means и EM-алгоритма на модельной выборке \"Mouse dataset\".\n",
    "\n",
    "![](img/clustering/img6.png)\n",
    "\n",
    "### Метод k-средних (k-Means)\n",
    "Простейшим методом кластеризации является $k$-средних (k-Mans), где $k$ - число кластеров, которые требуется выделить. \n",
    "Предполагается, что число $k$ известно.\n",
    "\n",
    "![](img/clustering/img7.png)\n",
    "\n",
    "В начале работы алгоритма выбираются $k$ случайных точек. Это точки играют роль центров кластеров: каждая точка будет отнесена к тому кластеру, расстояние до центра которого минимально. После этого выполняются итерации: на каждом шаге в качестве нового центра кластера выбирается среднее арифметическое всех точек, попавших в этот кластер, и обновляются метки кластеров ля точек в зависимости от близости к новым центрам кластеров. Итерации выполняются, пока не будет получен удовлетворительный результат.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Метод Bisect Means\n",
    "Если необходимо подобрать число кластеров, можно воспользоваться методом Bisect Means, который является модификацией метода k–средних.\n",
    "\n",
    "![](img/clustering/img8.png)\n",
    "\n",
    "Метод заключается в следующем. На первом шаге применяется метод 2-means, то есть метод k–средних в случае двух кластеров. После этого для точек из каждого из получившихся кластеров, если это необходимо, также запускается 2-means и кластер разбивается на два. Процедура продолжается до тех пор, пока есть такой кластер, который нужно дробить.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EM-алгоритм\n",
    "\n",
    "EM–алгоритм, другой метод кластеризации, заключается в максимизации правдоподобия. Он основан на том, что плотность вероятности распределения точек $p(x)$ выборки представляет собой взвешенную сумму плотностей вероятности $p_j(x)$ в каждом кластере:\n",
    "\n",
    "$$p(x) = \\sum_{j=1}^{K}w_{j}p_{j}(x),$$\n",
    "где веса $w_j \\geq 0$, а также $\\sum_{j=1}^{K}w_j=1$.\n",
    "\n",
    "При этом все $p_j(x)$ выбираются из некоторого семейства распределений $\\phi(\\theta; x)$ с параметром $\\theta$:\n",
    "$$p_j(x) = \\phi(\\theta_j; x).$$\n",
    "\n",
    "В качестве $\\phi(\\theta_j; x)$ часто выбирают семейство нормальных распределений.\n",
    "\n",
    "Алгоритм заключается в последовательном выполнении двух шагов:\n",
    "\n",
    "**E-шаг**: Вычисляются вспомогательные переменные:\n",
    "$$g_{ji}=p(\\theta_j \\mid x_i ) = \\frac{w_j p_j(x_i)}{p(x_i)}.$$\n",
    "Эти параметры фиксируются (так как в этом случае упрощается решение задачи максимизации).\n",
    "\n",
    "**M-шаг**: При зафиксированных $g_{ji}$ решение задачи максимизации правдоподобия может быть найдено согласно:\n",
    "$$w_j = \\frac{1}{N}\\sum_{i=1}^{N}g_{ij}, \\theta_j = \\arg\\max_{\\theta}\\sum_{i=1}^{N}g_{ji}\\ln \\phi(\\theta, x).$$\n",
    "\n",
    "Объект относится к кластеру $j$, для которого максимально значение $p(\\theta_j \\mid x_i)$.\n",
    "\n",
    "#### Алгоритм EM: замечание\n",
    "Действительно, данная задача представляет собой задачу разделения смеси распределений:\n",
    "$$p(x) = \\sum_{j=1}^{K}w_jp_j(x), p_j(x)=\\phi(\\theta_j ; x), $$\n",
    "\n",
    "в которой нужно оценить веса $w_j$ и параметры $\\theta_j$ отдельных компонентов. Эту задачу можно было бы попытаться решить напрямую, как \n",
    "$$w, \\theta = \\arg\\max_{\\theta, w} \\ln p(x_i).$$\n",
    "Но решение такой задачи найти крайне сложно и поэтому, в алгоритме EM-дополнительно фиксируются $g_{ij}$.\n",
    "\n",
    "Полное описание алгоритма достаточно сложное (не говоря уже о его понимании), но оно приведено в книге: \n",
    "*Elements of Statistical Learning* (link: https://statweb.stanford.edu/~tibs/ElemStatLearn/ ).\n",
    "\n",
    "![](https://cs7058.userapi.com/c836628/v836628756/38af0/HHfe53fLRXo.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Методы основанные на плотности точек\n",
    "Существуют так называемые методы, основанные на плотности точек (density-based), которые используют следующую идею. Для каждой точки выборки рассматривается её окрестность, причем:\n",
    "* Точка называется основной, если в ее окрестности много других точек (больше, чем некоторое число).\n",
    "* Точка называется пограничной, если в ее окрестности мало других точек, но среди них есть основная.\n",
    "* В ином случае точка называется шумовой.\n",
    "\n",
    "\n",
    "![](img/clustering/img9.png)\n",
    "Принцип работы алгоритма DBScan: изображены основная, пограничная и шумовые точки.\n",
    "\n",
    "DBSCAN — это один из density-based методов, который состоит из следующих шагов:\n",
    "1. Разделить точки на основные, пограничные и шумовые.\n",
    "* Отбросить шумовые точки.\n",
    "* Соединить основные точки, которые находятся на расстоянии \" друг от друга.\n",
    "* Каждую группу соединенных основных точек объединить в свой кластер.\n",
    "* Отнести пограничные точки к соответствующим им кластерам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Иерархическая кластеризация\n",
    "Еще один (уже вкратце разобранный) подход к кластеризации — иерархическая кластеризация. Он заключается в введении понятия расстояния между кластерами и состоит в следующем.\n",
    "В начале каждая точка относится к своему собственному кластеру. На каждом шаге алгоритма те кластеры, расстояние между которыми минимально, объединяются в один. Постепенно все кластеры объединяются в один, а процесс их объединения представляет собой дерево. Его можно изобразить с помощью так называемых дендрограмм. По горизонтальной оси дендрограммы отложено расстояние между кластерами в момент слияния, а по вертикальной — точки выборки.\n",
    "![](img/clustering/img10.png)\n",
    "\n",
    "В зависимости от требуемого числа кластеров, это дерево необходимо обрезать на определенной глубине.\n",
    "\n",
    "Важно, что изменение числа кластеров не требует перезапуска алгоритма, как это потребовалось бы в методе k-means.\n",
    "\n",
    "В биологии систематизация видов позволяет глубже понять их происхождение, представляет собой деление видов на определенные группы и этим сильно напоминает рассмотренную выше иерархическую кластеризацию.\n",
    "![](img/clustering/img11.png)\n",
    "\n",
    "Расстояние между кластерами можно вводить несколькими разными способами:\n",
    "* как среднее расстояние между объектами кластеров (Average linkage).\n",
    "* как максимальное расстояние между объектами кластеров (Complete linkage).\n",
    "* как минимальное расстояние между объектами кластеров (single linkage).\n",
    "\n",
    "![](img/clustering/img12.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обзор методов кластеризации\n",
    "Теперь можно систематизировать основные методы кластеризации. По получающейся структуре кластеров методы делятся на:\n",
    "* Иерархические, то есть характеризующиеся сложную структуру кластеров. Среди них выделяют:\n",
    "– Агломеративные, которые характеризуются последовательным объединением кластеров.\n",
    "– Дивизионные, которые заключаются в последовательном делении одного кластера, состоящего из всех объектов, на меньшие.\n",
    "* Плоские (не иерархические).\n",
    "Также некоторые методы кластеризации лучше работают на кластерах определенной формы. \n",
    "Также некоторые методы кластеризации позволяют сделать и жесткую, и мягкую кластеризацию, а некоторые — только жесткую."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример: Кластеризация текстов\n",
    "\n",
    "## Выборка и признаки\n",
    "\n",
    "Применим методы кластеризации на практике, на приммере выборки 20newsgroups из пакета sklearn. Эта выборка включает в себя множество писем на различные темы.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading dataset from http://people.csail.mit.edu/jrennie/20Newsgroups/20news-bydate.tar.gz (14 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "train_all = fetch_20newsgroups(subset='train')\n",
    "print(train_all.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате его исполнения был выведен список доступных тем. Для простоты ограничимся несколькими сильно различающимися темами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_dataset = fetch_20newsgroups(subset='train',\n",
    "                                   categories = ['comp.sys.mac.hardware',\n",
    "                                                'soc.religion.christian',\n",
    "                                                'rec.sport.hockey'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Просмотреть письмо, содержащиеся в обучающей выборке можно следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: erik@cheshire.oxy.edu (Erik Adams)\n",
      "Subject: HELP!!  My Macintosh \"luggable\" has lines on its screen!\n",
      "Organization: Occidental College, Los Angeles, CA 90041 USA.\n",
      "Distribution: comp\n",
      "Lines: 20\n",
      "\n",
      "Okay, I don't use it very much, but I would like for it to keep working\n",
      "correctly, at least as long as Apple continues to make System software\n",
      "that will run on it, if slowly :-)\n",
      "\n",
      "Here is the problem:  When the screen is tilted too far back, vertical\n",
      "lines appear on the screen.  They are every 10 pixels or so, and seem\n",
      "to be affected somewhat by opening windows and pulling down menus.\n",
      "It looks to a semi-technical person like there is a loose connection\n",
      "between the screen and the rest of the computer.\n",
      "\n",
      "I am open to suggestions that do not involve buying a new computer,\n",
      "or taking this one to the shop.  I would also like to not have\n",
      "to buy one of Larry Pina's books.  I like Larry, but I'm not sure\n",
      "I feel strongly enough about the computer to buy a service manual\n",
      "for it.\n",
      "\n",
      "On a related note:  what does the monitor connector connect to?\n",
      "\n",
      "Erik\n",
      "\n",
      "\n",
      "From: dlecoint@garnet.acns.fsu.edu (Darius_Lecointe)\n",
      "Subject: Re: Sabbath Admissions 5of5\n",
      "Organization: Florida State University\n",
      "Lines: 21\n",
      "\n",
      "I find it interesting that cls never answered any of the questions posed. \n",
      "Then he goes on the make statements which make me shudder.  He has\n",
      "established a two-tiered God.  One set of rules for the Jews (his people)\n",
      "and another set for the saved Gentiles (his people).  Why would God\n",
      "discriminate?  Does the Jew who accepts Jesus now have to live under the\n",
      "Gentile rules.\n",
      "\n",
      "God has one set of rules for all his people.  Paul was never against the\n",
      "law.  In fact he says repeatedly that faith establishes rather that annuls\n",
      "the law.  Paul's point is germane to both Jews and Greeks.  The Law can\n",
      "never be used as an instrument of salvation.  And please do not combine\n",
      "the ceremonial and moral laws in one.\n",
      "\n",
      "In Matt 5:14-19 Christ plainly says what He came to do and you say He was\n",
      "only saying that for the Jews's benefit.  Your Christ must be a\n",
      "politician, speaking from both sides of His mouth.  As Paul said, \"I have\n",
      "not so learned Christ.\"  Forget all the theology, just do what Jesus says.\n",
      " Your excuses will not hold up in a court of law on earth, far less in\n",
      "God's judgement hall.\n",
      "\n",
      "Darius\n",
      "\n",
      "From: scialdone@nssdca.gsfc.nasa.gov (John Scialdone)\n",
      "Subject: CUT Vukota and Pilon!!!\n",
      "News-Software: VAX/VMS VNEWS 1.41    \n",
      "Organization: NASA - Goddard Space Flight Center\n",
      "Lines: 32\n",
      "\n",
      "I have been to all 3 Isles/Caps tilts at the Crap Centre this year, all Isles\n",
      "wins and there is no justification for Vukota and Pilon to play for the Isles.\n",
      "Vukota is absolutely the worst puck handler in the world!! He couldn't hit a\n",
      "bull in the ass with a banjo!! Al must remember a few years back when Mick \n",
      "scored 3 goals in one period against the Caps in a 5-3 Isles win. I was there\n",
      "and was astonished as was the rest of the crowd. Wake-up Al!!! Years later he's\n",
      "gotten worse. He's a cheap shot artist and always ends up getting\n",
      "stupid/senseless penalties. I think he would make a good police officier!!!\n",
      "\n",
      "As for Pilon, he can't carry the puck out to center ice by himself. He either\n",
      "makes a bad pass resulting in a turnover, or he attempts to bring the puck \n",
      "towards the neutral zone and skates right into an opposing skater. He can't\n",
      "stay on his skates with most forwards or centers. He either falls down or \n",
      "committs a penalty. Call up somebody from Capital District AL!!!!!\n",
      "\n",
      "As far as the playoffs, the Isles are as difficult to figure out as the Caps.\n",
      "Two good teams with talent but so inconsistent. They should meet in the first\n",
      "round. The Isles seem to play up to the level of their competition so they\n",
      "should play well against Jersey tonite. It'll probably be another tight 1-goal\n",
      "game as the last 20 games hve been for the Isles. I wish when the get a lead\n",
      "they could continue to pour it on instead of settling back into a defensive\n",
      "shell and letting the opposition get back in the game. Al MUST understand he\n",
      "can't do with this team what he did with the 80-83 Isles. maybe Al should got\n",
      "to. Where is Bobby Nystrom?? Clark Gilles?? John Tonelli?? These are the kind\n",
      "of young minds we need behing the bench!!    FIRE AL!!!!\n",
      "\n",
      "John Scialdone\n",
      "SCIALDONE@NSSDCA.GSFC.NASA.GOV\n",
      "\n",
      "**********When your ship comes in, first man takes the Sail********************\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Вывести первое письмо в выборке\n",
    "print(simple_dataset.data[0])\n",
    "\n",
    "\n",
    "# Вывести последнее письмо в выборке\n",
    "print(simple_dataset.data[-1])\n",
    "\n",
    "\n",
    "# Вывести предпоследнее письмо в выборке\n",
    "print(simple_dataset.data[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Темы писем содержатся в массиве \n",
    "    target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_dataset.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полное количество объектов в выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1777\n"
     ]
    }
   ],
   "source": [
    "print(len(simple_dataset.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве признаков можно использовать частоты слов \n",
    "    CountVectorizer\n",
    "или взвешенные частоты слов \n",
    "    TfidfVectorizer.\n",
    "Следующий код подключает необходимые функции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В обоих случаях, чтобы обеспечить небольшое количество признаков,ь можно установить максимальный и минимальный пороги для документной частоты слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_df=500, min_df=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку слова, которые встречаются почти во всех письмах или, наоборот, очень редко, вряд ли будут полезны, но, отбросив их, можно существенно упростить задачу с вычислительной точки зрения.\n",
    "\n",
    "После этого можно создать матрицу \"объект-признак\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix = vectorizer.fit_transform(simple_dataset.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Размер этой матрицы при данном способе построения признакового описания:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1777, 3767)\n"
     ]
    }
   ],
   "source": [
    "print(matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Т. е. в данном случае используется 3767 признаков. Получить список созданных признаков можно сл. командой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '01',\n",
       " '02',\n",
       " '03',\n",
       " '030',\n",
       " '0358',\n",
       " '04',\n",
       " '040',\n",
       " '05',\n",
       " '06',\n",
       " '07',\n",
       " '08',\n",
       " '09',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '101',\n",
       " '102',\n",
       " '104',\n",
       " '105',\n",
       " '106',\n",
       " '109',\n",
       " '11',\n",
       " '110',\n",
       " '112',\n",
       " '113',\n",
       " '119',\n",
       " '12',\n",
       " '120',\n",
       " '126',\n",
       " '127',\n",
       " '128',\n",
       " '129',\n",
       " '13',\n",
       " '132',\n",
       " '133',\n",
       " '14',\n",
       " '140',\n",
       " '15',\n",
       " '150',\n",
       " '152',\n",
       " '16',\n",
       " '160',\n",
       " '17',\n",
       " '170',\n",
       " '175',\n",
       " '18',\n",
       " '180',\n",
       " '19',\n",
       " '1987',\n",
       " '1988',\n",
       " '1989',\n",
       " '199',\n",
       " '1990',\n",
       " '1991',\n",
       " '1992',\n",
       " '1993',\n",
       " '1993apr14',\n",
       " '1993apr15',\n",
       " '1993apr16',\n",
       " '1993apr18',\n",
       " '1993apr19',\n",
       " '1993apr20',\n",
       " '1993apr5',\n",
       " '1993apr6',\n",
       " '1d17',\n",
       " '1d20',\n",
       " '1st',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '203',\n",
       " '21',\n",
       " '210',\n",
       " '22',\n",
       " '23',\n",
       " '230',\n",
       " '24',\n",
       " '240',\n",
       " '241',\n",
       " '25',\n",
       " '253',\n",
       " '256',\n",
       " '25mhz',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '286',\n",
       " '29',\n",
       " '2nd',\n",
       " '30',\n",
       " '300',\n",
       " '30602',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '34',\n",
       " '35',\n",
       " '36',\n",
       " '37',\n",
       " '38',\n",
       " '386',\n",
       " '39',\n",
       " '3rd',\n",
       " '40',\n",
       " '400',\n",
       " '403',\n",
       " '408',\n",
       " '41',\n",
       " '42',\n",
       " '43',\n",
       " '44',\n",
       " '45',\n",
       " '46',\n",
       " '47',\n",
       " '48',\n",
       " '486',\n",
       " '49',\n",
       " '4mb',\n",
       " '4th',\n",
       " '50',\n",
       " '500',\n",
       " '51',\n",
       " '512',\n",
       " '512k',\n",
       " '52',\n",
       " '53',\n",
       " '54',\n",
       " '542',\n",
       " '55',\n",
       " '56',\n",
       " '57',\n",
       " '58',\n",
       " '59',\n",
       " '5of5',\n",
       " '5th',\n",
       " '60',\n",
       " '600',\n",
       " '61',\n",
       " '610',\n",
       " '62',\n",
       " '63',\n",
       " '64',\n",
       " '65',\n",
       " '650',\n",
       " '66',\n",
       " '67',\n",
       " '68',\n",
       " '68030',\n",
       " '68040',\n",
       " '680x0',\n",
       " '69',\n",
       " '6th',\n",
       " '70',\n",
       " '700',\n",
       " '706',\n",
       " '71',\n",
       " '72',\n",
       " '73',\n",
       " '74',\n",
       " '7415',\n",
       " '75',\n",
       " '76',\n",
       " '77',\n",
       " '78',\n",
       " '79',\n",
       " '7th',\n",
       " '80',\n",
       " '800',\n",
       " '80ns',\n",
       " '81',\n",
       " '82',\n",
       " '83',\n",
       " '84',\n",
       " '85',\n",
       " '86',\n",
       " '87',\n",
       " '88',\n",
       " '89',\n",
       " '90',\n",
       " '900',\n",
       " '91',\n",
       " '92',\n",
       " '93',\n",
       " '94',\n",
       " '95',\n",
       " '950',\n",
       " '96',\n",
       " '97',\n",
       " '9760',\n",
       " '98',\n",
       " '99',\n",
       " '__',\n",
       " '___',\n",
       " '____',\n",
       " 'aa888',\n",
       " 'aaron',\n",
       " 'ab',\n",
       " 'abc',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'abo',\n",
       " 'above',\n",
       " 'abraham',\n",
       " 'absence',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absolutes',\n",
       " 'ac',\n",
       " 'academic',\n",
       " 'acc',\n",
       " 'accelerator',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'access',\n",
       " 'according',\n",
       " 'account',\n",
       " 'accounts',\n",
       " 'accurate',\n",
       " 'achieve',\n",
       " 'achkar',\n",
       " 'acknowledge',\n",
       " 'acns',\n",
       " 'acquired',\n",
       " 'across',\n",
       " 'acs',\n",
       " 'acsu',\n",
       " 'act',\n",
       " 'action',\n",
       " 'actions',\n",
       " 'active',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'adams',\n",
       " 'adapter',\n",
       " 'adb',\n",
       " 'add',\n",
       " 'added',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'address',\n",
       " 'addresses',\n",
       " 'adirondack',\n",
       " 'admissions',\n",
       " 'admit',\n",
       " 'adopt',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advantage',\n",
       " 'advice',\n",
       " 'affected',\n",
       " 'afford',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'after',\n",
       " 'afternoon',\n",
       " 'again',\n",
       " 'against',\n",
       " 'age',\n",
       " 'agnostic',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'agreement',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'ahl',\n",
       " 'ai',\n",
       " 'aids',\n",
       " 'air',\n",
       " 'aisun3',\n",
       " 'al',\n",
       " 'alan',\n",
       " 'alberta',\n",
       " 'alchemy',\n",
       " 'alexander',\n",
       " 'alive',\n",
       " 'allen',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allows',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alot',\n",
       " 'alpha',\n",
       " 'already',\n",
       " 'also',\n",
       " 'alt',\n",
       " 'alternative',\n",
       " 'although',\n",
       " 'altogether',\n",
       " 'alvin',\n",
       " 'always',\n",
       " 'am',\n",
       " 'am2x',\n",
       " 'amateur',\n",
       " 'amazing',\n",
       " 'ambiguous',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americans',\n",
       " 'among',\n",
       " 'amount',\n",
       " 'amour',\n",
       " 'analysis',\n",
       " 'ancient',\n",
       " 'anderson',\n",
       " 'andersson',\n",
       " 'andrew',\n",
       " 'andreychuk',\n",
       " 'andy',\n",
       " 'angeles',\n",
       " 'angels',\n",
       " 'anger',\n",
       " 'angry',\n",
       " 'animals',\n",
       " 'ann',\n",
       " 'anna',\n",
       " 'announce',\n",
       " 'announced',\n",
       " 'announcer',\n",
       " 'announcers',\n",
       " 'annoying',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'answering',\n",
       " 'answers',\n",
       " 'antonio',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anytime',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'apart',\n",
       " 'apologize',\n",
       " 'apostle',\n",
       " 'apostles',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appear',\n",
       " 'appeared',\n",
       " 'appears',\n",
       " 'apple',\n",
       " 'applelink',\n",
       " 'appletalk',\n",
       " 'application',\n",
       " 'applications',\n",
       " 'applied',\n",
       " 'applies',\n",
       " 'apply',\n",
       " 'appointed',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'approach',\n",
       " 'appropriate',\n",
       " 'approved',\n",
       " 'apr',\n",
       " 'april',\n",
       " 'aps',\n",
       " 'aquinas',\n",
       " 'arbor',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'aren',\n",
       " 'arena',\n",
       " 'argue',\n",
       " 'arguing',\n",
       " 'argument',\n",
       " 'arguments',\n",
       " 'army',\n",
       " 'around',\n",
       " 'arrogance',\n",
       " 'arrogant',\n",
       " 'art',\n",
       " 'articles',\n",
       " 'artificial',\n",
       " 'arts',\n",
       " 'ashley',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'asks',\n",
       " 'aspect',\n",
       " 'aspects',\n",
       " 'ass',\n",
       " 'assertion',\n",
       " 'assist',\n",
       " 'assistant',\n",
       " 'assists',\n",
       " 'associate',\n",
       " 'associated',\n",
       " 'association',\n",
       " 'assume',\n",
       " 'assumed',\n",
       " 'assuming',\n",
       " 'assumption',\n",
       " 'astray',\n",
       " 'atheism',\n",
       " 'atheist',\n",
       " 'atheists',\n",
       " 'athena',\n",
       " 'athens',\n",
       " 'athos',\n",
       " 'atlanta',\n",
       " 'att',\n",
       " 'attack',\n",
       " 'attempt',\n",
       " 'attempted',\n",
       " 'attempting',\n",
       " 'attempts',\n",
       " 'attendance',\n",
       " 'attention',\n",
       " 'atterlep',\n",
       " 'attitude',\n",
       " 'au',\n",
       " 'audience',\n",
       " 'austin',\n",
       " 'australia',\n",
       " 'author',\n",
       " 'authorities',\n",
       " 'authority',\n",
       " 'authors',\n",
       " 'auto',\n",
       " 'available',\n",
       " 'ave',\n",
       " 'avenue',\n",
       " 'average',\n",
       " 'avoid',\n",
       " 'awarded',\n",
       " 'awards',\n",
       " 'aware',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'axelsson',\n",
       " 'back',\n",
       " 'background',\n",
       " 'backup',\n",
       " 'bad',\n",
       " 'baker',\n",
       " 'ball',\n",
       " 'ballentine',\n",
       " 'baltimore',\n",
       " 'band',\n",
       " 'baptism',\n",
       " 'barrasso',\n",
       " 'base',\n",
       " 'baseball',\n",
       " 'based',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basis',\n",
       " 'basketball',\n",
       " 'battery',\n",
       " 'battle',\n",
       " 'bay',\n",
       " 'bbs',\n",
       " 'bc',\n",
       " 'bear',\n",
       " 'bears',\n",
       " 'beat',\n",
       " 'beautiful',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beg',\n",
       " 'began',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'begins',\n",
       " 'behalf',\n",
       " 'behavior',\n",
       " 'behaviour',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'beings',\n",
       " 'belfour',\n",
       " 'belief',\n",
       " 'beliefs',\n",
       " 'believe',\n",
       " 'believed',\n",
       " 'believers',\n",
       " 'believes',\n",
       " 'believing',\n",
       " 'bell',\n",
       " 'bellows',\n",
       " 'belong',\n",
       " 'below',\n",
       " 'bench',\n",
       " 'benefit',\n",
       " 'beranek',\n",
       " 'berkeley',\n",
       " 'bernoulli',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'bet',\n",
       " 'better',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'bgsu',\n",
       " 'bgu',\n",
       " 'biased',\n",
       " 'bible',\n",
       " 'biblical',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bill',\n",
       " 'birth',\n",
       " 'bishop',\n",
       " 'bit',\n",
       " 'bitnet',\n",
       " 'bits',\n",
       " 'black',\n",
       " 'blackhawks',\n",
       " 'blame',\n",
       " 'bless',\n",
       " 'blessed',\n",
       " 'blind',\n",
       " 'blindly',\n",
       " 'block',\n",
       " 'blood',\n",
       " 'blow',\n",
       " 'blue',\n",
       " 'blues',\n",
       " 'bnr',\n",
       " 'board',\n",
       " 'boarding',\n",
       " 'boards',\n",
       " 'bob',\n",
       " 'bobby',\n",
       " 'body',\n",
       " 'book',\n",
       " 'books',\n",
       " 'bookstore',\n",
       " 'boot',\n",
       " 'born',\n",
       " 'bos',\n",
       " 'boss',\n",
       " 'boston',\n",
       " 'both',\n",
       " 'bother',\n",
       " 'bothers',\n",
       " 'bottom',\n",
       " 'bought',\n",
       " 'boulder',\n",
       " 'bound',\n",
       " 'boundary',\n",
       " 'bourque',\n",
       " 'bowling',\n",
       " 'box',\n",
       " 'boxes',\n",
       " 'boy',\n",
       " 'brad',\n",
       " 'bradley',\n",
       " 'brain',\n",
       " 'branch',\n",
       " 'brand',\n",
       " 'braves',\n",
       " 'break',\n",
       " 'breaker',\n",
       " 'breaking',\n",
       " 'brent',\n",
       " 'breton',\n",
       " 'bri',\n",
       " 'brian',\n",
       " 'brief',\n",
       " 'brind',\n",
       " 'bring',\n",
       " 'brings',\n",
       " 'british',\n",
       " 'broadcast',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'brother',\n",
       " 'brothers',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'bruce',\n",
       " 'bruins',\n",
       " 'brunswick',\n",
       " 'bryan',\n",
       " 'btw',\n",
       " 'bu',\n",
       " 'buddhism',\n",
       " 'buddhist',\n",
       " 'buf',\n",
       " 'buffalo',\n",
       " 'bug',\n",
       " 'build',\n",
       " 'building',\n",
       " 'built',\n",
       " 'bunch',\n",
       " 'bure',\n",
       " 'burnaby',\n",
       " 'burned',\n",
       " 'burns',\n",
       " 'bus',\n",
       " 'business',\n",
       " 'butt',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'buying',\n",
       " 'byler',\n",
       " 'bytes',\n",
       " 'c610',\n",
       " 'c650',\n",
       " 'ca',\n",
       " 'cable',\n",
       " 'cables',\n",
       " 'cache',\n",
       " 'cadkey',\n",
       " 'cage',\n",
       " 'cal',\n",
       " 'calder',\n",
       " 'calgary',\n",
       " 'california',\n",
       " 'call',\n",
       " 'called',\n",
       " 'calling',\n",
       " 'calls',\n",
       " 'calvin',\n",
       " 'cam',\n",
       " 'came',\n",
       " 'camp',\n",
       " 'campbell',\n",
       " 'campus',\n",
       " 'canada',\n",
       " 'canadian',\n",
       " 'canadians',\n",
       " 'canadiens',\n",
       " 'cannot',\n",
       " 'canon',\n",
       " 'canucks',\n",
       " 'capability',\n",
       " 'capable',\n",
       " 'capacity',\n",
       " 'cape',\n",
       " 'capital',\n",
       " 'capitals',\n",
       " 'caps',\n",
       " 'captain',\n",
       " 'captains',\n",
       " 'car',\n",
       " 'caralv',\n",
       " 'card',\n",
       " 'cardinal',\n",
       " 'cards',\n",
       " 'care',\n",
       " 'career',\n",
       " 'careful',\n",
       " 'carefully',\n",
       " 'cares',\n",
       " 'carleton',\n",
       " 'carnegie',\n",
       " 'carol',\n",
       " 'carolina',\n",
       " 'carpenter',\n",
       " 'carried',\n",
       " 'carry',\n",
       " 'carrying',\n",
       " 'carson',\n",
       " 'cartridge',\n",
       " 'case',\n",
       " 'cases',\n",
       " 'cassels',\n",
       " 'cast',\n",
       " 'category',\n",
       " 'catholic',\n",
       " 'catholics',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'caused',\n",
       " 'causes',\n",
       " 'cb',\n",
       " 'cbc',\n",
       " 'cbnewsh',\n",
       " 'cbnewsk',\n",
       " 'cc',\n",
       " 'ccu',\n",
       " 'cd',\n",
       " 'cd300',\n",
       " 'cec1',\n",
       " 'celebrate',\n",
       " 'cent',\n",
       " 'center',\n",
       " 'central',\n",
       " 'centre',\n",
       " 'centris',\n",
       " 'centuries',\n",
       " 'century',\n",
       " 'ceremonial',\n",
       " 'ceremony',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'certainty',\n",
       " 'cf',\n",
       " 'cgsvax',\n",
       " 'chain',\n",
       " 'champions',\n",
       " 'championship',\n",
       " 'championships',\n",
       " 'champs',\n",
       " 'chance',\n",
       " 'chances',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'changes',\n",
       " 'changing',\n",
       " 'channel',\n",
       " 'chapter',\n",
       " 'character',\n",
       " 'charge',\n",
       " 'charles',\n",
       " 'charlie',\n",
       " 'cheap',\n",
       " 'cheaper',\n",
       " 'check',\n",
       " 'checked',\n",
       " 'checking',\n",
       " 'cheers',\n",
       " 'chelios',\n",
       " 'chem',\n",
       " 'chemistry',\n",
       " 'cherry',\n",
       " 'chhabra',\n",
       " 'chi',\n",
       " 'chicago',\n",
       " 'chief',\n",
       " 'child',\n",
       " 'children',\n",
       " 'chip',\n",
       " 'chips',\n",
       " 'choice',\n",
       " 'choices',\n",
       " 'choose',\n",
       " 'choosing',\n",
       " 'chose',\n",
       " 'chosen',\n",
       " 'chris',\n",
       " 'christ',\n",
       " 'christian',\n",
       " 'christianity',\n",
       " 'christians',\n",
       " 'christopher',\n",
       " 'chuck',\n",
       " 'church',\n",
       " 'churches',\n",
       " 'ciccarelli',\n",
       " 'circle',\n",
       " 'circumstances',\n",
       " 'cis',\n",
       " 'cited',\n",
       " 'cities',\n",
       " 'city',\n",
       " 'civil',\n",
       " 'claim',\n",
       " 'claimed',\n",
       " 'claiming',\n",
       " 'claims',\n",
       " 'claremont',\n",
       " 'clark',\n",
       " 'clarke',\n",
       " 'clarkson',\n",
       " 'class',\n",
       " 'classic',\n",
       " 'classy',\n",
       " 'claude',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'clearly',\n",
       " 'clement',\n",
       " 'cleveland',\n",
       " 'clh',\n",
       " 'clinton',\n",
       " 'clock',\n",
       " 'close',\n",
       " 'closed',\n",
       " 'closely',\n",
       " 'closer',\n",
       " 'closest',\n",
       " 'club',\n",
       " 'cmu',\n",
       " 'co',\n",
       " 'coach',\n",
       " 'coaches',\n",
       " 'coaching',\n",
       " 'code',\n",
       " 'coffey',\n",
       " 'cohen',\n",
       " 'col',\n",
       " 'collection',\n",
       " 'college',\n",
       " 'collingridge',\n",
       " 'color',\n",
       " 'colorado',\n",
       " 'colors',\n",
       " 'colostate',\n",
       " 'colour',\n",
       " 'columbia',\n",
       " 'com',\n",
       " 'combination',\n",
       " 'combined',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'comics',\n",
       " 'coming',\n",
       " 'command',\n",
       " 'commandments',\n",
       " 'commands',\n",
       " 'comment',\n",
       " 'commentary',\n",
       " 'comments',\n",
       " 'commitment',\n",
       " 'committed',\n",
       " 'common',\n",
       " 'communication',\n",
       " 'communications',\n",
       " 'communion',\n",
       " 'community',\n",
       " 'comp',\n",
       " 'companies',\n",
       " 'company',\n",
       " 'comparable',\n",
       " 'comparative',\n",
       " 'compare',\n",
       " 'compared',\n",
       " 'comparing',\n",
       " 'comparison',\n",
       " 'compatible',\n",
       " 'complain',\n",
       " 'complete',\n",
       " 'completed',\n",
       " 'completely',\n",
       " 'complex',\n",
       " 'complicated',\n",
       " 'compuserve',\n",
       " 'computer',\n",
       " 'computers',\n",
       " 'computing',\n",
       " 'con',\n",
       " 'concept',\n",
       " 'conception',\n",
       " 'concern',\n",
       " 'concerned',\n",
       " 'concerning',\n",
       " 'conclude',\n",
       " 'conclusion',\n",
       " 'conclusions',\n",
       " 'condemned',\n",
       " 'conditions',\n",
       " 'conditt',\n",
       " 'conference',\n",
       " 'configuration',\n",
       " 'conflict',\n",
       " 'confused',\n",
       " 'confusing',\n",
       " 'confusion',\n",
       " 'congregation',\n",
       " 'connect',\n",
       " 'connected',\n",
       " 'connection',\n",
       " 'connector',\n",
       " 'consecutive',\n",
       " 'consensus',\n",
       " 'conservative',\n",
       " 'consider',\n",
       " 'considered',\n",
       " 'considering',\n",
       " 'consistent',\n",
       " 'consistently',\n",
       " 'constant',\n",
       " 'constantly',\n",
       " 'consultant',\n",
       " 'contact',\n",
       " 'contained',\n",
       " 'contains',\n",
       " 'content',\n",
       " 'context',\n",
       " 'continent',\n",
       " 'continue',\n",
       " 'continued',\n",
       " 'continues',\n",
       " 'contract',\n",
       " 'contradict',\n",
       " 'contradiction',\n",
       " 'contradictory',\n",
       " 'contrary',\n",
       " 'contribution',\n",
       " 'control',\n",
       " 'conversion',\n",
       " 'convert',\n",
       " 'converted',\n",
       " 'convictions',\n",
       " 'convince',\n",
       " 'cook',\n",
       " 'cool',\n",
       " 'coos',\n",
       " 'copies',\n",
       " 'coprocessor',\n",
       " 'copy',\n",
       " 'cor',\n",
       " 'cordially',\n",
       " 'corinthians',\n",
       " 'corner',\n",
       " 'corp',\n",
       " 'corporation',\n",
       " 'correct',\n",
       " 'correctly',\n",
       " 'cost',\n",
       " 'costs',\n",
       " 'cote',\n",
       " 'could',\n",
       " 'couldn',\n",
       " 'council',\n",
       " 'count',\n",
       " 'counted',\n",
       " 'countries',\n",
       " 'country',\n",
       " 'couple',\n",
       " 'course',\n",
       " 'court',\n",
       " 'courtnall',\n",
       " 'cover',\n",
       " 'coverage',\n",
       " 'covered',\n",
       " 'covington',\n",
       " 'cpu',\n",
       " 'craft',\n",
       " 'craig',\n",
       " 'crap',\n",
       " 'crashes',\n",
       " 'craven',\n",
       " 'crazy',\n",
       " 'create',\n",
       " 'created',\n",
       " 'creation',\n",
       " 'creator',\n",
       " 'credit',\n",
       " 'critical',\n",
       " 'criticism',\n",
       " 'cross',\n",
       " 'crowd',\n",
       " 'cs',\n",
       " 'csd',\n",
       " 'cso',\n",
       " 'cu',\n",
       " 'cullen',\n",
       " 'cult',\n",
       " 'cultural',\n",
       " 'culture',\n",
       " 'cunixb',\n",
       " 'cunixc',\n",
       " 'cup',\n",
       " 'cups',\n",
       " 'curious',\n",
       " 'current',\n",
       " 'currently',\n",
       " 'curtis',\n",
       " 'cut',\n",
       " 'cwis',\n",
       " 'cwru',\n",
       " 'czech',\n",
       " 'd88',\n",
       " 'dahlen',\n",
       " 'daily',\n",
       " 'dal',\n",
       " 'dale',\n",
       " 'dalhousie',\n",
       " 'dallas',\n",
       " 'damn',\n",
       " 'damphousse',\n",
       " 'dan',\n",
       " 'danger',\n",
       " 'dangerous',\n",
       " 'daniel',\n",
       " 'dare',\n",
       " 'darius',\n",
       " 'darius_lecointe',\n",
       " 'darren',\n",
       " 'dartmouth',\n",
       " 'daryl',\n",
       " ...]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Метод K-средних\n",
    "\n",
    "Рассмотрим в действии метод кластеризации K-средних:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "model = KMeans(n_clusters=3, random_state=42)\n",
    "preds = model.fit_predict(matrix.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь\n",
    "    random_state\n",
    "полностью определяет случайные значения, которые используются в методе K-средних. Это необходимо для обеспечения воспроизводимости результатов.\n",
    "\n",
    "Результат выполнения алгоритма и истинные значения ответов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ..., 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Результат кластеризации\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ..., 0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Истинные ответы\n",
    "print(simple_dataset.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем перенумерацию кластеров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping = {2 : 1, 1: 2, 0: 0}\n",
    "mapped_preds = [mapping[pred] for pred in preds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь подсчитаем долю случае, когда тема была определена некорректно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6741699493528419\n"
     ]
    }
   ],
   "source": [
    "print(float(sum(mapped_preds != simple_dataset.target)) / len(simple_dataset.target))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся классификатором на тех же данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.978039526759\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "clf = LogisticRegression()\n",
    "print(cross_val_score(clf, matrix, simple_dataset.target).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To be continued...\n",
    "\n",
    "## Литература:\n",
    "* https://www.analyticsvidhya.com/blog/2016/11/an-introduction-to-clustering-and-different-methods-of-clustering/\n",
    "* https://www.analyticsvidhya.com/blog/2013/11/getting-clustering-right/\n",
    "* https://www.analyticsvidhya.com/blog/2013/11/getting-clustering-right-part-ii/\n",
    "* Coursera Курс \"Поиск структуры в данных\" специализации Анализ данных : https://www.coursera.org/learn/unsupervised-learning\n",
    "* Introduction to Statistical Learning\n",
    "* Elements of Statistical Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
